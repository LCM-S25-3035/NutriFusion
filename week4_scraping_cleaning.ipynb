{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tCYiXa-UgV8",
        "outputId": "48eac4e3-4753-4120-c1f5-d3eb83a22693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Scraped and saved recipes with estimated nutrition to 'themealdb_recipes.csv'\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# ----- STEP 1: Nutrition lookup table (you can expand this) -----\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken breast': {'calories': 165, 'fat': 3.6, 'protein': 31, 'fiber': 0},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'fiber': 2.1},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'fiber': 0.4},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'fiber': 0},\n",
        "    'salt': {'calories': 0, 'fat': 0, 'protein': 0, 'fiber': 0},\n",
        "    'pepper': {'calories': 251, 'fat': 3.3, 'protein': 10.4, 'fiber': 25.3},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'fiber': 1.2},\n",
        "    'carrot': {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'fiber': 2.8}\n",
        "    # Add more ingredients as needed\n",
        "}\n",
        "\n",
        "# ----- STEP 2: API access functions -----\n",
        "def get_meals_by_category(category='Chicken'):\n",
        "    url = f\"https://www.themealdb.com/api/json/v1/1/filter.php?c={category}\"\n",
        "    response = requests.get(url)\n",
        "    return response.json().get('meals', [])\n",
        "\n",
        "def get_meal_details(meal_id):\n",
        "    url = f\"https://www.themealdb.com/api/json/v1/1/lookup.php?i={meal_id}\"\n",
        "    response = requests.get(url)\n",
        "    meals = response.json().get('meals', [])\n",
        "    return meals[0] if meals else {}\n",
        "\n",
        "# ----- STEP 3: Ingredient extraction -----\n",
        "def extract_ingredients(meal):\n",
        "    ingredients = {}\n",
        "    for i in range(1, 21):\n",
        "        ing = meal.get(f\"strIngredient{i}\")\n",
        "        meas = meal.get(f\"strMeasure{i}\")\n",
        "        if ing and ing.strip():\n",
        "            ingredients[ing.strip().lower()] = meas.strip() if meas else ''\n",
        "    return ingredients\n",
        "\n",
        "# ----- STEP 4: Nutrition estimation -----\n",
        "def estimate_nutrition(ingredients):\n",
        "    totals = {'calories': 0, 'fat': 0, 'protein': 0, 'fiber': 0}\n",
        "    for ing in ingredients:\n",
        "        for known in NUTRITION_TABLE:\n",
        "            if known in ing:  # fuzzy match\n",
        "                nut = NUTRITION_TABLE[known]\n",
        "                for key in totals:\n",
        "                    totals[key] += nut.get(key, 0)\n",
        "    return totals\n",
        "\n",
        "# ----- STEP 5: Main scraping + saving -----\n",
        "def scrape_meals(category='Chicken', limit=5):\n",
        "    meals = get_meals_by_category(category)\n",
        "    meal_data = []\n",
        "\n",
        "    for meal in meals[:limit]:\n",
        "        details = get_meal_details(meal['idMeal'])\n",
        "        ingredients = extract_ingredients(details)\n",
        "        nutrition = estimate_nutrition(ingredients.keys())\n",
        "\n",
        "        data = {\n",
        "            'MealID': meal['idMeal'],\n",
        "            'Meal': details.get('strMeal'),\n",
        "            'Category': details.get('strCategory'),\n",
        "            'Area': details.get('strArea'),\n",
        "            'Instructions': details.get('strInstructions'),\n",
        "            'Tags': details.get('strTags'),\n",
        "            'YouTube': details.get('strYoutube'),\n",
        "            'Ingredients': ingredients,\n",
        "            'Calories': nutrition['calories'],\n",
        "            'Fat': nutrition['fat'],\n",
        "            'Protein': nutrition['protein'],\n",
        "            'Fiber': nutrition['fiber'],\n",
        "        }\n",
        "        meal_data.append(data)\n",
        "\n",
        "    return pd.DataFrame(meal_data)\n",
        "\n",
        "# ----- STEP 6: Run and save -----\n",
        "if __name__ == \"__main__\":\n",
        "    df_recipes = scrape_meals(category='Chicken', limit=5)\n",
        "    df_recipes.to_csv(\"themealdb_recipes.csv\", index=False)\n",
        "    print(\"‚úÖ Scraped and saved recipes with estimated nutrition to 'themealdb_recipes.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Nutrition lookup table (simplified per 100g; customize/expand as needed)\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken':     {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice':        {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion':       {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic':      {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato':      {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk':        {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter':      {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'carrot':      {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'carbs': 10, 'sugar': 4.7, 'fiber': 2.8},\n",
        "    'egg':         {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "    'salt':        {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "}\n",
        "\n",
        "def get_all_meal_ids():\n",
        "    meal_ids = set()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        url = f'https://www.themealdb.com/api/json/v1/1/search.php?f={letter}'\n",
        "        res = requests.get(url)\n",
        "        meals = res.json().get('meals', [])\n",
        "        for meal in meals:\n",
        "            meal_ids.add(meal['idMeal'])\n",
        "        time.sleep(0.5)  # gentle delay\n",
        "    return list(meal_ids)\n",
        "\n",
        "def get_meal_details(meal_id):\n",
        "    url = f\"https://www.themealdb.com/api/json/v1/1/lookup.php?i={meal_id}\"\n",
        "    response = requests.get(url)\n",
        "    meals = response.json().get('meals', [])\n",
        "    return meals[0] if meals else None\n",
        "\n",
        "def extract_ingredients(meal):\n",
        "    ingredients = []\n",
        "    for i in range(1, 21):\n",
        "        ing = meal.get(f\"strIngredient{i}\")\n",
        "        if ing and ing.strip():\n",
        "            ingredients.append(ing.strip().lower())\n",
        "    return ingredients\n",
        "\n",
        "def estimate_nutrition(ingredients):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    for ing in ingredients:\n",
        "        for known in NUTRITION_TABLE:\n",
        "            if known in ing:\n",
        "                for key in total:\n",
        "                    total[key] += NUTRITION_TABLE[known][key]\n",
        "    return total\n",
        "\n",
        "def scrape_meals(limit=500):\n",
        "    all_ids = get_all_meal_ids()\n",
        "    recipes = []\n",
        "    for meal_id in all_ids[:limit]:\n",
        "        meal = get_meal_details(meal_id)\n",
        "        if meal:\n",
        "            ingredients = extract_ingredients(meal)\n",
        "            nutrition = estimate_nutrition(ingredients)\n",
        "            recipes.append({\n",
        "                'MealID': meal_id,\n",
        "                'Meal': meal.get('strMeal'),\n",
        "                'Category': meal.get('strCategory'),\n",
        "                'Area': meal.get('strArea'),\n",
        "                'Instructions': meal.get('strInstructions'),\n",
        "                'Ingredients': ', '.join(ingredients),\n",
        "                'Calories': nutrition['calories'],\n",
        "                'Fat': nutrition['fat'],\n",
        "                'Protein': nutrition['protein'],\n",
        "                'Sugar': nutrition['sugar'],\n",
        "                'Fiber': nutrition['fiber'],\n",
        "                'Carbohydrates': nutrition['carbs']\n",
        "            })\n",
        "        time.sleep(0.2)\n",
        "    return pd.DataFrame(recipes)\n",
        "\n",
        "# Run the scraper\n",
        "df = scrape_meals(limit=500)\n",
        "df.to_csv(\"themealdb_500_recipes.csv\", index=False)\n",
        "print(\"‚úÖ Scraped 500 recipes from TheMealDB and saved with  nutrients.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "_9_N4x_oVh9v",
        "outputId": "b3942ba5-477c-47c0-9270-e703cafa0a44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ed92aeb91eaf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Run the scraper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_meals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"themealdb_500_recipes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Scraped 500 recipes from TheMealDB and saved with  nutrients.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ed92aeb91eaf>\u001b[0m in \u001b[0;36mscrape_meals\u001b[0;34m(limit)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscrape_meals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mall_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_meal_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mrecipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmeal_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ed92aeb91eaf>\u001b[0m in \u001b[0;36mget_all_meal_ids\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmeals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'meals'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmeal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mmeal_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'idMeal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# gentle delay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Simplified nutrient lookup table (approximate per 100g)\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'carrot': {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'carbs': 10, 'sugar': 4.7, 'fiber': 2.8},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "    'salt': {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "}\n",
        "\n",
        "def get_all_meal_ids():\n",
        "    meal_ids = set()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        url = f'https://www.themealdb.com/api/json/v1/1/search.php?f={letter}'\n",
        "        res = requests.get(url)\n",
        "        data = res.json()\n",
        "        meals = data.get('meals', [])\n",
        "        if meals:  # ‚úÖ Prevents TypeError when meals is None\n",
        "            for meal in meals:\n",
        "                meal_ids.add(meal['idMeal'])\n",
        "        time.sleep(0.3)\n",
        "    return list(meal_ids)\n",
        "\n",
        "def get_meal_details(meal_id):\n",
        "    url = f\"https://www.themealdb.com/api/json/v1/1/lookup.php?i={meal_id}\"\n",
        "    response = requests.get(url)\n",
        "    meals = response.json().get('meals', [])\n",
        "    return meals[0] if meals else None\n",
        "\n",
        "def extract_ingredients(meal):\n",
        "    ingredients = []\n",
        "    for i in range(1, 21):\n",
        "        ing = meal.get(f\"strIngredient{i}\")\n",
        "        if ing and ing.strip():\n",
        "            ingredients.append(ing.strip().lower())\n",
        "    return ingredients\n",
        "\n",
        "def estimate_nutrition(ingredients):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    for ing in ingredients:\n",
        "        for known in NUTRITION_TABLE:\n",
        "            if known in ing:\n",
        "                for key in total:\n",
        "                    total[key] += NUTRITION_TABLE[known][key]\n",
        "    return total\n",
        "\n",
        "def scrape_meals(limit=500):\n",
        "    all_ids = get_all_meal_ids()\n",
        "    recipes = []\n",
        "    for meal_id in all_ids[:limit]:\n",
        "        meal = get_meal_details(meal_id)\n",
        "        if meal:\n",
        "            ingredients = extract_ingredients(meal)\n",
        "            nutrition = estimate_nutrition(ingredients)\n",
        "            recipes.append({\n",
        "                'MealID': meal_id,\n",
        "                'Meal': meal.get('strMeal'),\n",
        "                'Category': meal.get('strCategory'),\n",
        "                'Area': meal.get('strArea'),\n",
        "                'Instructions': meal.get('strInstructions'),\n",
        "                'Ingredients': ', '.join(ingredients),\n",
        "                'Calories': nutrition['calories'],\n",
        "                'Fat': nutrition['fat'],\n",
        "                'Protein': nutrition['protein'],\n",
        "                'Sugar': nutrition['sugar'],\n",
        "                'Fiber': nutrition['fiber'],\n",
        "                'Carbohydrates': nutrition['carbs']\n",
        "            })\n",
        "        time.sleep(0.2)\n",
        "    return pd.DataFrame(recipes)\n",
        "\n",
        "# Run the scraper\n",
        "df = scrape_meals(limit=500)\n",
        "df.to_csv(\"themealdb_500_recipes.csv\", index=False)\n",
        "print(\"‚úÖ Done! Scraped 500 recipes from TheMealDB with estimated nutrition.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQT8mYaHWFdC",
        "outputId": "9fb7d773-19c8-4357-d342-0860558d995d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done! Scraped 500 recipes from TheMealDB with estimated nutrition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "# Nutritional lookup (approx. per 100g)\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'carrot': {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'carbs': 10, 'sugar': 4.7, 'fiber': 2.8},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "    'salt': {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "}\n",
        "\n",
        "# Headless browser setup for scraping\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--user-data-dir=/tmp/bbc-profile')  # avoids SessionNotCreatedException\n",
        "\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "def get_bbc_recipe_links(pages=50):\n",
        "    links = set()\n",
        "    for page in range(1, pages + 1):\n",
        "        print(f\"üîç Fetching page {page}\")\n",
        "        url = f\"https://www.bbcgoodfood.com/recipes/category/all?page={page}\"\n",
        "        driver.get(url)\n",
        "        time.sleep(2)\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        for a in soup.select('h2.heading-4 a'):\n",
        "            href = a.get('href')\n",
        "            if href and '/recipes/' in href:\n",
        "                links.add(\"https://www.bbcgoodfood.com\" + href)\n",
        "    return list(links)\n",
        "\n",
        "def extract_ingredients_from_bbc(soup):\n",
        "    return [li.text.strip().lower() for li in soup.select('.ingredients-section li') if li.text.strip()]\n",
        "\n",
        "def estimate_nutrition(ingredients):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    for ing in ingredients:\n",
        "        for known in NUTRITION_TABLE:\n",
        "            if known in ing:\n",
        "                for key in total:\n",
        "                    total[key] += NUTRITION_TABLE[known][key]\n",
        "    return total\n",
        "\n",
        "def get_bbc_recipe_details(url):\n",
        "    try:\n",
        "        driver.get(url)\n",
        "        time.sleep(2)\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        title = soup.select_one('h1').text.strip()\n",
        "        ingredients = extract_ingredients_from_bbc(soup)\n",
        "        method = ' '.join([step.text.strip() for step in soup.select('.method__item')])\n",
        "        nutrition = estimate_nutrition(ingredients)\n",
        "        return {\n",
        "            'Meal': title,\n",
        "            'URL': url,\n",
        "            'Ingredients': ', '.join(ingredients),\n",
        "            'Instructions': method,\n",
        "            'Calories': nutrition['calories'],\n",
        "            'Fat': nutrition['fat'],\n",
        "            'Protein': nutrition['protein'],\n",
        "            'Sugar': nutrition['sugar'],\n",
        "            'Fiber': nutrition['fiber'],\n",
        "            'Carbohydrates': nutrition['carbs']\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error scraping {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def scrape_bbc_meals(limit=500):\n",
        "    links = get_bbc_recipe_links(pages=50)\n",
        "    print(f\"Found {len(links)} recipes.\")\n",
        "    recipes = []\n",
        "    for i, url in enumerate(links[:limit]):\n",
        "        print(f\"‚è≥ Scraping {i+1}/{limit}\")\n",
        "        meal = get_bbc_recipe_details(url)\n",
        "        if meal:\n",
        "            recipes.append(meal)\n",
        "        time.sleep(1)\n",
        "    return pd.DataFrame(recipes)\n",
        "\n",
        "# Run scraper\n",
        "df = scrape_bbc_meals(limit=500)\n",
        "df.to_csv(\"bbc_good_food_500_recipes.csv\", index=False)\n",
        "print(\"‚úÖ Done! Scraped 500 BBC Good Food recipes with estimated nutrition.\")\n",
        "\n",
        "driver.quit()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_27a1sSau38",
        "outputId": "30fea336-ca0b-42f2-aada-2d5344e65993"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Fetching page 1\n",
            "üîç Fetching page 2\n",
            "üîç Fetching page 3\n",
            "üîç Fetching page 4\n",
            "üîç Fetching page 5\n",
            "üîç Fetching page 6\n",
            "üîç Fetching page 7\n",
            "üîç Fetching page 8\n",
            "üîç Fetching page 9\n",
            "üîç Fetching page 10\n",
            "üîç Fetching page 11\n",
            "üîç Fetching page 12\n",
            "üîç Fetching page 13\n",
            "üîç Fetching page 14\n",
            "üîç Fetching page 15\n",
            "üîç Fetching page 16\n",
            "üîç Fetching page 17\n",
            "üîç Fetching page 18\n",
            "üîç Fetching page 19\n",
            "üîç Fetching page 20\n",
            "üîç Fetching page 21\n",
            "üîç Fetching page 22\n",
            "üîç Fetching page 23\n",
            "üîç Fetching page 24\n",
            "üîç Fetching page 25\n",
            "üîç Fetching page 26\n",
            "üîç Fetching page 27\n",
            "üîç Fetching page 28\n",
            "üîç Fetching page 29\n",
            "üîç Fetching page 30\n",
            "üîç Fetching page 31\n",
            "üîç Fetching page 32\n",
            "üîç Fetching page 33\n",
            "üîç Fetching page 34\n",
            "üîç Fetching page 35\n",
            "üîç Fetching page 36\n",
            "üîç Fetching page 37\n",
            "üîç Fetching page 38\n",
            "üîç Fetching page 39\n",
            "üîç Fetching page 40\n",
            "üîç Fetching page 41\n",
            "üîç Fetching page 42\n",
            "üîç Fetching page 43\n",
            "üîç Fetching page 44\n",
            "üîç Fetching page 45\n",
            "üîç Fetching page 46\n",
            "üîç Fetching page 47\n",
            "üîç Fetching page 48\n",
            "üîç Fetching page 49\n",
            "üîç Fetching page 50\n",
            "Found 0 recipes.\n",
            "‚úÖ Done! Scraped 500 BBC Good Food recipes with estimated nutrition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Simple nutrition lookup table (expand as needed)\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "}\n",
        "\n",
        "def get_recipe_links(pages=25):\n",
        "    links = []\n",
        "    for i in range(1, pages + 1):\n",
        "        url = f\"https://www.allrecipes.com/recipes/?page={i}\"\n",
        "        res = requests.get(url)\n",
        "        soup = BeautifulSoup(res.content, 'html.parser')\n",
        "        for a in soup.select('a.card__titleLink'):\n",
        "            link = a.get('href')\n",
        "            if link and 'https://www.allrecipes.com/recipe/' in link:\n",
        "                links.append(link)\n",
        "        time.sleep(0.5)\n",
        "    return list(set(links))\n",
        "\n",
        "def extract_recipe(url):\n",
        "    res = requests.get(url)\n",
        "    soup = BeautifulSoup(res.content, 'html.parser')\n",
        "\n",
        "    name = soup.find('h1', class_='headline').text.strip() if soup.find('h1', class_='headline') else 'N/A'\n",
        "    ingredients_tags = soup.select('span.ingredients-item-name')\n",
        "    ingredients = [i.text.strip().lower() for i in ingredients_tags if i.text.strip()]\n",
        "    instructions_tag = soup.select('ul.instructions-section li p')\n",
        "    instructions = ' '.join(i.text.strip() for i in instructions_tag)\n",
        "\n",
        "    nutrition = estimate_nutrition(ingredients)\n",
        "    return {\n",
        "        'Meal': name,\n",
        "        'Ingredients': ', '.join(ingredients),\n",
        "        'Instructions': instructions,\n",
        "        'Calories': nutrition['calories'],\n",
        "        'Fat': nutrition['fat'],\n",
        "        'Protein': nutrition['protein'],\n",
        "        'Sugar': nutrition['sugar'],\n",
        "        'Fiber': nutrition['fiber'],\n",
        "        'Carbohydrates': nutrition['carbs']\n",
        "    }\n",
        "\n",
        "def estimate_nutrition(ingredients):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    for ing in ingredients:\n",
        "        for known in NUTRITION_TABLE:\n",
        "            if known in ing:\n",
        "                for key in total:\n",
        "                    total[key] += NUTRITION_TABLE[known][key]\n",
        "    return total\n",
        "\n",
        "def scrape_allrecipes(limit=500):\n",
        "    links = get_recipe_links(pages=40)\n",
        "    data = []\n",
        "    for i, link in enumerate(links[:limit]):\n",
        "        try:\n",
        "            print(f\"Scraping ({i+1}/{limit}): {link}\")\n",
        "            recipe = extract_recipe(link)\n",
        "            data.append(recipe)\n",
        "            time.sleep(0.4)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error scraping {link}: {e}\")\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Scrape and Save\n",
        "df = scrape_allrecipes(limit=500)\n",
        "df.to_csv(\"allrecipes_500.csv\", index=False)\n",
        "print(\"‚úÖ Done! Saved 500 recipes from AllRecipes.com.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfRIXFGzccoZ",
        "outputId": "4764d3e4-39d0-4dc4-8545-5d57694005f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done! Saved 500 recipes from AllRecipes.com.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "82m9HRfhiN2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bBn_7am9iTVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Nutrition lookup table (can be expanded)\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
        "}\n",
        "\n",
        "def get_recipe_links(pages=20):\n",
        "    links = set()\n",
        "    for page in range(1, pages + 1):\n",
        "        url = f'https://www.allrecipes.com/recipes/?page={page}'\n",
        "        res = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(res.content, 'html.parser')\n",
        "        for tag in soup.find_all('a', href=True):\n",
        "            href = tag['href']\n",
        "            if href.startswith(\"https://www.allrecipes.com/recipe/\") and href.count('/') >= 5:\n",
        "                links.add(href.split(\"?\")[0])  # remove tracking params\n",
        "        time.sleep(0.5)\n",
        "    return list(links)\n",
        "\n",
        "def extract_recipe(url):\n",
        "    res = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(res.content, 'html.parser')\n",
        "\n",
        "    try:\n",
        "        name = soup.find('h1').text.strip()\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "    ingredients = [i.text.strip().lower() for i in soup.select('span.ingredients-item-name') if i.text.strip()]\n",
        "    instructions = ' '.join([i.text.strip() for i in soup.select('ul.instructions-section li p')])\n",
        "\n",
        "    nutrition = estimate_nutrition(ingredients)\n",
        "\n",
        "    return {\n",
        "        'Meal': name,\n",
        "        'Ingredients': ', '.join(ingredients),\n",
        "        'Instructions': instructions,\n",
        "        'Calories': nutrition['calories'],\n",
        "        'Fat': nutrition['fat'],\n",
        "        'Protein': nutrition['protein'],\n",
        "        'Sugar': nutrition['sugar'],\n",
        "        'Fiber': nutrition['fiber'],\n",
        "        'Carbohydrates': nutrition['carbs']\n",
        "    }\n",
        "\n",
        "def estimate_nutrition(ingredients):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    for ing in ingredients:\n",
        "        for known in NUTRITION_TABLE:\n",
        "            if known in ing:\n",
        "                for key in total:\n",
        "                    total[key] += NUTRITION_TABLE[known][key]\n",
        "    return total\n",
        "\n",
        "def scrape_allrecipes(limit=500):\n",
        "    links = get_recipe_links(pages=30)\n",
        "    print(f\"üîó Found {len(links)} recipe links\")\n",
        "    data = []\n",
        "    for i, link in enumerate(links[:limit]):\n",
        "        print(f\"Scraping {i+1}/{limit}: {link}\")\n",
        "        recipe = extract_recipe(link)\n",
        "        if recipe:\n",
        "            data.append(recipe)\n",
        "        time.sleep(0.4)\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Run scraper\n",
        "df = scrape_allrecipes(limit=500)\n",
        "df.to_csv(\"allrecipes_500_recipes.csv\", index=False)\n",
        "print(\"‚úÖ Done! Scraped\", len(df), \"recipes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udn1NzrbdEzj",
        "outputId": "8b1cc355-c5b8-4279-f3c6-709514b5fd24"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó Found 0 recipe links\n",
            "‚úÖ Done! Scraped 0 recipes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install recipe-scrapers pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icpv-vgIdu9L",
        "outputId": "9598963d-5289-42a9-f193-f9cdaec55f50"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting recipe-scrapers\n",
            "  Downloading recipe_scrapers-15.7.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from recipe-scrapers) (4.13.4)\n",
            "Collecting extruct>=0.17.0 (from recipe-scrapers)\n",
            "  Downloading extruct-0.18.0-py2.py3-none-any.whl.metadata (36 kB)\n",
            "Collecting isodate>=0.6.1 (from recipe-scrapers)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.12.3->recipe-scrapers) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.12.3->recipe-scrapers) (4.13.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from extruct>=0.17.0->recipe-scrapers) (5.4.0)\n",
            "Collecting lxml-html-clean (from extruct>=0.17.0->recipe-scrapers)\n",
            "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting rdflib>=6.0.0 (from extruct>=0.17.0->recipe-scrapers)\n",
            "  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pyrdfa3 (from extruct>=0.17.0->recipe-scrapers)\n",
            "  Downloading pyRdfa3-3.6.4-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting mf2py (from extruct>=0.17.0->recipe-scrapers)\n",
            "  Downloading mf2py-2.0.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting w3lib (from extruct>=0.17.0->recipe-scrapers)\n",
            "  Downloading w3lib-2.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting html-text>=0.5.1 (from extruct>=0.17.0->recipe-scrapers)\n",
            "  Downloading html_text-0.7.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting jstyleson (from extruct>=0.17.0->recipe-scrapers)\n",
            "  Downloading jstyleson-0.0.2.tar.gz (2.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib>=6.0.0->extruct>=0.17.0->recipe-scrapers) (3.2.3)\n",
            "Requirement already satisfied: html5lib<2.0,>=1.1 in /usr/local/lib/python3.11/dist-packages (from mf2py->extruct>=0.17.0->recipe-scrapers) (1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.2 in /usr/local/lib/python3.11/dist-packages (from mf2py->extruct>=0.17.0->recipe-scrapers) (2.32.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib<2.0,>=1.1->mf2py->extruct>=0.17.0->recipe-scrapers) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.2->mf2py->extruct>=0.17.0->recipe-scrapers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.2->mf2py->extruct>=0.17.0->recipe-scrapers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.2->mf2py->extruct>=0.17.0->recipe-scrapers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.2->mf2py->extruct>=0.17.0->recipe-scrapers) (2025.4.26)\n",
            "Downloading recipe_scrapers-15.7.1-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m254.2/254.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading extruct-0.18.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading html_text-0.7.0-py3-none-any.whl (8.1 kB)\n",
            "Downloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading mf2py-2.0.1-py3-none-any.whl (25 kB)\n",
            "Downloading pyRdfa3-3.6.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading w3lib-2.3.1-py3-none-any.whl (21 kB)\n",
            "Building wheels for collected packages: jstyleson\n",
            "  Building wheel for jstyleson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jstyleson: filename=jstyleson-0.0.2-py3-none-any.whl size=2383 sha256=b7e7c9ddf53c36a681ae2337164038a542d91674a3a9cc39916a4090a720c2f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/63/0e/50090147fb424100f7d9078b71c21b9e7468b6f643515a60d6\n",
            "Successfully built jstyleson\n",
            "Installing collected packages: jstyleson, w3lib, rdflib, lxml-html-clean, isodate, pyrdfa3, mf2py, html-text, extruct, recipe-scrapers\n",
            "Successfully installed extruct-0.18.0 html-text-0.7.0 isodate-0.7.2 jstyleson-0.0.2 lxml-html-clean-0.4.2 mf2py-2.0.1 pyrdfa3-3.6.4 rdflib-7.1.4 recipe-scrapers-15.7.1 w3lib-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from recipe_scrapers import scrape_me\n",
        "\n",
        "# Simplified nutrient lookup table (approximate per 100g)\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'carrot': {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'carbs': 10, 'sugar': 4.7, 'fiber': 2.8},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "    'salt': {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "}\n",
        "\n",
        "def estimate_nutrition(ingredients):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    for ing in ingredients:\n",
        "        for known in NUTRITION_TABLE:\n",
        "            if known in ing.lower():\n",
        "                for key in total:\n",
        "                    total[key] += NUTRITION_TABLE[known][key]\n",
        "    return total\n",
        "\n",
        "def scrape_recipes(urls):\n",
        "    recipes = []\n",
        "    for url in urls:\n",
        "        try:\n",
        "            scraper = scrape_me(url)\n",
        "            title = scraper.title()\n",
        "            ingredients = scraper.ingredients()\n",
        "            instructions = scraper.instructions()\n",
        "            nutrition = estimate_nutrition(ingredients)\n",
        "            recipes.append({\n",
        "                'Title': title,\n",
        "                'Ingredients': ', '.join(ingredients),\n",
        "                'Instructions': instructions,\n",
        "                'Calories': nutrition['calories'],\n",
        "                'Fat': nutrition['fat'],\n",
        "                'Protein': nutrition['protein'],\n",
        "                'Sugar': nutrition['sugar'],\n",
        "                'Fiber': nutrition['fiber'],\n",
        "                'Carbohydrates': nutrition['carbs']\n",
        "            })\n",
        "            time.sleep(0.2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping {url}: {e}\")\n",
        "    return pd.DataFrame(recipes)\n",
        "\n",
        "# Example list of recipe URLs\n",
        "recipe_urls = [\n",
        "    'https://www.allrecipes.com/recipe/158968/spinach-and-feta-turkey-burgers/',\n",
        "    'https://www.allrecipes.com/recipe/24074/alysias-basic-meat-lasagna/',\n",
        "    'https://www.allrecipes.com/recipe/229960/chef-johns-chicken-parmesan/',\n",
        "    # Add more URLs as needed\n",
        "]\n",
        "\n",
        "# Run the scraper\n",
        "df = scrape_recipes(recipe_urls)\n",
        "df.to_csv(\"recipes_dataset.csv\", index=False)\n",
        "print(f\"‚úÖ Done! Scraped {len(df)} recipes with estimated nutrition.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmtWrtT_dy--",
        "outputId": "5d9055dc-d163-497f-c75c-2ffebc222e7b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error scraping https://www.allrecipes.com/recipe/229960/chef-johns-chicken-parmesan/: HTTP Error 404: Not Found\n",
            "‚úÖ Done! Scraped 2 recipes with estimated nutrition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Recipe1M dataset\n",
        "with open('recipes.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Simplified nutrient lookup table (approximate per 100g)\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'carrot': {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'carbs': 10, 'sugar': 4.7, 'fiber': 2.8},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "    'salt': {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "}\n",
        "\n",
        "def estimate_nutrition(ingredients):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    for ing in ingredients:\n",
        "        for known in NUTRITION_TABLE:\n",
        "            if known in ing.lower():\n",
        "                for key in total:\n",
        "                    total[key] += NUTRITION_TABLE[known][key]\n",
        "    return total\n",
        "\n",
        "# Process the first 500 recipes\n",
        "recipes = []\n",
        "for recipe in data[:500]:\n",
        "    title = recipe.get('title', '')\n",
        "    ingredients = recipe.get('ingredients', [])\n",
        "    instructions = recipe.get('instructions', '')\n",
        "    nutrition = estimate_nutrition(ingredients)\n",
        "    recipes.append({\n",
        "        'Title': title,\n",
        "        'Ingredients': ', '.join(ingredients),\n",
        "        'Instructions': instructions,\n",
        "        'Calories': nutrition['calories'],\n",
        "        'Fat': nutrition['fat'],\n",
        "        'Protein': nutrition['protein'],\n",
        "        'Sugar': nutrition['sugar'],\n",
        "        'Fiber': nutrition['fiber'],\n",
        "        'Carbohydrates': nutrition['carbs']\n",
        "    })\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(recipes)\n",
        "df.to_csv(\"recipe1m_500_recipes.csv\", index=False)\n",
        "print(f\"‚úÖ Done! Processed {len(df)} recipes with estimated nutrition.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "34V-3xnneSnM",
        "outputId": "ff695178-0eb1-4bd4-c51d-21e691740991"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'recipes.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-14cfde4b8fa4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the Recipe1M dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recipes.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'recipes.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Simplified nutrition table (per 100g approx)\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'carrot': {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'carbs': 10, 'sugar': 4.7, 'fiber': 2.8},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "    'salt': {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "}\n",
        "\n",
        "def estimate_nutrition(ingredients):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    for ing in ingredients:\n",
        "        ing_lower = ing.lower()\n",
        "        for known in NUTRITION_TABLE:\n",
        "            if known in ing_lower:\n",
        "                for key in total:\n",
        "                    total[key] += NUTRITION_TABLE[known][key]\n",
        "    return total\n",
        "\n",
        "def load_and_process_json(filename='layer1.json', limit=500):\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"‚ùå File '{filename}' not found. Please upload or download it first.\")\n",
        "        return None\n",
        "\n",
        "    with open(filename, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    recipes = []\n",
        "    for item in data[:limit]:\n",
        "        title = item.get('title', '').strip()\n",
        "        instructions = item.get('instructions', '')\n",
        "        ingredients = [i.get('text', '').strip() for i in item.get('ingredients', [])]\n",
        "        nutrition = estimate_nutrition(ingredients)\n",
        "\n",
        "        recipes.append({\n",
        "            'Title': title,\n",
        "            'Instructions': instructions,\n",
        "            'Ingredients': ', '.join(ingredients),\n",
        "            'Calories': nutrition['calories'],\n",
        "            'Fat': nutrition['fat'],\n",
        "            'Protein': nutrition['protein'],\n",
        "            'Sugar': nutrition['sugar'],\n",
        "            'Fiber': nutrition['fiber'],\n",
        "            'Carbohydrates': nutrition['carbs']\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(recipes)\n",
        "    df.to_csv(\"recipe1m_500_recipes.csv\", index=False)\n",
        "    print(f\"‚úÖ Saved {len(df)} recipes to 'recipe1m_500_recipes.csv'\")\n",
        "    return df\n",
        "\n",
        "# Run the loader\n",
        "df = load_and_process_json('layer1.json')  # Change filename if needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwFzq-Q3eprr",
        "outputId": "38868bbf-bce3-43e1-f359-b2fcd54374aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå File 'layer1.json' not found. Please upload or download it first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download sample layer1.json (~500 recipes)\n",
        "!wget -O layer1.json https://huggingface.co/datasets/ashraq/recipe-nlg/resolve/main/sample_layer1.json\n",
        "\n",
        "# Step 2: Import required libraries\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Step 3: Define nutrition table (per 100g, simplified)\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'carrot': {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'carbs': 10, 'sugar': 4.7, 'fiber': 2.8},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "    'salt': {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "}\n",
        "\n",
        "# Step 4: Load layer1.json and extract recipes\n",
        "with open(\"layer1.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "recipes = []\n",
        "for item in data[:500]:  # limit to 500 recipes\n",
        "    title = item.get(\"title\", \"\")\n",
        "    instructions = item.get(\"instructions\", \"\")\n",
        "    ingredients = [ing[\"text\"].lower() for ing in item.get(\"ingredients\", [])]\n",
        "\n",
        "    # Estimate nutrition\n",
        "    nutrition = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    for ing in ingredients:\n",
        "        for known in NUTRITION_TABLE:\n",
        "            if known in ing:\n",
        "                for key in nutrition:\n",
        "                    nutrition[key] += NUTRITION_TABLE[known][key]\n",
        "\n",
        "    recipes.append({\n",
        "        \"Title\": title,\n",
        "        \"Instructions\": instructions,\n",
        "        \"Ingredients\": \", \".join(ingredients),\n",
        "        \"Calories\": nutrition['calories'],\n",
        "        \"Fat\": nutrition['fat'],\n",
        "        \"Protein\": nutrition['protein'],\n",
        "        \"Sugar\": nutrition['sugar'],\n",
        "        \"Fiber\": nutrition['fiber'],\n",
        "        \"Carbohydrates\": nutrition['carbs']\n",
        "    })\n",
        "\n",
        "# Step 5: Save to CSV\n",
        "df = pd.DataFrame(recipes)\n",
        "df.to_csv(\"recipe1m_sample_500.csv\", index=False)\n",
        "print(\"‚úÖ Done! Saved 500 recipes with estimated nutrition to 'recipe1m_sample_500.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "5GWj4OXhe-Nv",
        "outputId": "b1c78d2e-1efe-4163-8ecd-8a85926e3d86"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-03 01:50:51--  https://huggingface.co/datasets/ashraq/recipe-nlg/resolve/main/sample_layer1.json\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.4, 18.172.134.88, 18.172.134.124, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "\n",
            "Username/Password Authentication Failed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e74fbc23a920>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Step 4: Load layer1.json and extract recipes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layer1.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mrecipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/TheMealDB_with_nutrition.csv')\n",
        "\n",
        "# Simple nutrition lookup table\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "    'salt': {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'carrot': {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'carbs': 10, 'sugar': 4.7, 'fiber': 2.8}\n",
        "}\n",
        "\n",
        "# Helper function to estimate nutrition\n",
        "def estimate_nutrition(ingredient_text):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    if isinstance(ingredient_text, str):\n",
        "        ingredients = [i.strip().lower() for i in ingredient_text.split(',')]\n",
        "        for ing in ingredients:\n",
        "            for known in NUTRITION_TABLE:\n",
        "                if known in ing:\n",
        "                    for key in total:\n",
        "                        total[key] += NUTRITION_TABLE[known][key]\n",
        "    return pd.Series(total)\n",
        "\n",
        "# Apply estimation to each row\n",
        "nutrition_df = df['Ingredients'].apply(estimate_nutrition)\n",
        "\n",
        "# Merge with original DataFrame\n",
        "df_updated = pd.concat([df, nutrition_df], axis=1)\n",
        "\n",
        "# Save new dataset\n",
        "df_updated.to_csv(\"/content/TheMealDB_with_nutrition.csv\", index=False)\n",
        "print(\"‚úÖ Estimated nutrition added and saved as 'TheMealDB_with_estimated_nutrition.csv'\")\n"
      ],
      "metadata": {
        "id": "nj-z8tAoiXU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/TheMealDB_with_nutrition.csv')\n",
        "\n",
        "# Simple nutrition lookup table\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "    'salt': {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'carrot': {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'carbs': 10, 'sugar': 4.7, 'fiber': 2.8}\n",
        "}\n",
        "\n",
        "# Helper function to estimate nutrition\n",
        "def estimate_nutrition(ingredient_text):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    if isinstance(ingredient_text, str):\n",
        "        ingredients = [i.strip().lower() for i in ingredient_text.split(',')]\n",
        "        for ing in ingredients:\n",
        "            for known in NUTRITION_TABLE:\n",
        "                if known in ing:\n",
        "                    for key in total:\n",
        "                        total[key] += NUTRITION_TABLE[known][key]\n",
        "    return pd.Series(total)\n",
        "\n",
        "# Apply estimation to each row\n",
        "nutrition_df = df['Ingredients'].apply(estimate_nutrition)\n",
        "\n",
        "# Merge with original DataFrame\n",
        "df_updated = pd.concat([df, nutrition_df], axis=1)\n",
        "\n",
        "# Save new dataset\n",
        "df_updated.to_csv(\"/content/TheMealDB_with_nutrition.csv\", index=False)\n",
        "print(\"‚úÖ Estimated nutrition added and saved as 'TheMealDB_with_estimated_nutrition.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Naw9FVF-jTKi",
        "outputId": "99c881e3-a975-4ace-ef47-8d437b8f3ec4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Estimated nutrition added and saved as 'TheMealDB_with_estimated_nutrition.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/all_mealdb_recipes_120+.csv')\n",
        "\n",
        "# Simple nutrition lookup table\n",
        "NUTRITION_TABLE = {\n",
        "    'chicken': {'calories': 239, 'fat': 14, 'protein': 27, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'rice': {'calories': 130, 'fat': 0.3, 'protein': 2.7, 'carbs': 28, 'sugar': 0.1, 'fiber': 0.4},\n",
        "    'onion': {'calories': 40, 'fat': 0.1, 'protein': 1.1, 'carbs': 9.3, 'sugar': 4.2, 'fiber': 1.7},\n",
        "    'garlic': {'calories': 149, 'fat': 0.5, 'protein': 6.4, 'carbs': 33, 'sugar': 1, 'fiber': 2.1},\n",
        "    'tomato': {'calories': 18, 'fat': 0.2, 'protein': 0.9, 'carbs': 3.9, 'sugar': 2.6, 'fiber': 1.2},\n",
        "    'milk': {'calories': 42, 'fat': 1, 'protein': 3.4, 'carbs': 5, 'sugar': 5, 'fiber': 0},\n",
        "    'butter': {'calories': 717, 'fat': 81, 'protein': 0.9, 'carbs': 0.1, 'sugar': 0.1, 'fiber': 0},\n",
        "    'egg': {'calories': 155, 'fat': 11, 'protein': 13, 'carbs': 1.1, 'sugar': 1.1, 'fiber': 0},\n",
        "    'salt': {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0},\n",
        "    'carrot': {'calories': 41, 'fat': 0.2, 'protein': 0.9, 'carbs': 10, 'sugar': 4.7, 'fiber': 2.8}\n",
        "}\n",
        "\n",
        "# Function to estimate nutrition from ingredients\n",
        "def estimate_nutrition(ingredient_text):\n",
        "    total = {'calories': 0, 'fat': 0, 'protein': 0, 'carbs': 0, 'sugar': 0, 'fiber': 0}\n",
        "    if isinstance(ingredient_text, str):\n",
        "        ingredients = [i.strip().lower() for i in ingredient_text.split(',')]\n",
        "        for ing in ingredients:\n",
        "            for known in NUTRITION_TABLE:\n",
        "                if known in ing:\n",
        "                    for key in total:\n",
        "                        total[key] += NUTRITION_TABLE[known][key]\n",
        "    return pd.Series(total)\n",
        "\n",
        "# Apply nutrition estimation\n",
        "nutrition_df = df['Ingredients'].apply(estimate_nutrition)\n",
        "\n",
        "# Combine nutrition info with original data\n",
        "df_updated = pd.concat([df, nutrition_df], axis=1)\n",
        "\n",
        "# Save updated DataFrame to CSV\n",
        "output_path = \"/content/all_mealdb_recipes_120+.csv\"\n",
        "df_updated.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Nutrition estimation complete and saved to: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiPYxFjSlR01",
        "outputId": "dd907501-ddec-4070-8279-c2088ebe8bef"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Nutrition estimation complete and saved to: /content/all_mealdb_recipes_120+.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/themealdb_recipes.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Show basic info before cleaning\n",
        "print(\"Before cleaning:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Strip whitespace and standardize column names\n",
        "df.columns = df.columns.str.strip()\n",
        "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
        "\n",
        "# Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Remove leading/trailing spaces in string columns\n",
        "for col in df.select_dtypes(include='object'):\n",
        "    df[col] = df[col].str.strip()\n",
        "\n",
        "# Handle missing values\n",
        "# Option 1: Drop rows where essential columns (e.g., name, ingredients) are missing\n",
        "essential_columns = ['meal', 'ingredients']  # Update if necessary\n",
        "df = df.dropna(subset=[col for col in essential_columns if col in df.columns])\n",
        "\n",
        "# Option 2 (optional): Fill missing values in non-essential columns\n",
        "df = df.fillna('Unknown')  # Or use specific values depending on column\n",
        "\n",
        "# Normalize text: lowercase for relevant fields\n",
        "for col in ['meal', 'category', 'area', 'ingredients']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].str.lower()\n",
        "\n",
        "# Save cleaned dataset\n",
        "cleaned_path = '/content/themealdb_recipes.csv'\n",
        "df.to_csv(cleaned_path, index=False)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n‚úÖ Dataset cleaned and saved to:\", cleaned_path)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z_gw0SFmpwl",
        "outputId": "0ffb0568-be91-4a6a-92a1-50e0fe958a21"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before cleaning:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 12 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   MealID        5 non-null      int64  \n",
            " 1   Meal          5 non-null      object \n",
            " 2   Category      5 non-null      object \n",
            " 3   Area          5 non-null      object \n",
            " 4   Instructions  5 non-null      object \n",
            " 5   Tags          1 non-null      object \n",
            " 6   YouTube       5 non-null      object \n",
            " 7   Ingredients   5 non-null      object \n",
            " 8   Calories      5 non-null      int64  \n",
            " 9   Fat           5 non-null      float64\n",
            " 10  Protein       5 non-null      float64\n",
            " 11  Fiber         5 non-null      float64\n",
            "dtypes: float64(3), int64(2), object(7)\n",
            "memory usage: 612.0+ bytes\n",
            "None\n",
            "\n",
            "Missing values per column:\n",
            " MealID          0\n",
            "Meal            0\n",
            "Category        0\n",
            "Area            0\n",
            "Instructions    0\n",
            "Tags            4\n",
            "YouTube         0\n",
            "Ingredients     0\n",
            "Calories        0\n",
            "Fat             0\n",
            "Protein         0\n",
            "Fiber           0\n",
            "dtype: int64\n",
            "\n",
            "‚úÖ Dataset cleaned and saved to: /content/themealdb_recipes.csv\n",
            "   mealid                                  meal category       area  \\\n",
            "0   53085  15-minute chicken & halloumi burgers  chicken   american   \n",
            "1   53050                           ayam percik  chicken  malaysian   \n",
            "2   52940                    brown stew chicken  chicken   jamaican   \n",
            "3   53016                  chick-fil-a sandwich  chicken   american   \n",
            "4   52846             chicken & mushroom hotpot  chicken    british   \n",
            "\n",
            "                                        instructions     tags  \\\n",
            "0  STEP 1\\r\\n\\r\\nPut the chicken breasts between ...  Unknown   \n",
            "1  In a blender, add the ingredients for the spic...  Unknown   \n",
            "2  Squeeze lime over chicken and rub well. Drain ...     Stew   \n",
            "3  Wrap the chicken loosely between plastic wrap ...  Unknown   \n",
            "4  Heat oven to 200C/180C fan/gas 6. Put the butt...  Unknown   \n",
            "\n",
            "                                       youtube  \\\n",
            "0  https://www.youtube.com/watch?v=k9Ez0bUbXKc   \n",
            "1  https://www.youtube.com/watch?v=9ytR28QK6I8   \n",
            "2  https://www.youtube.com/watch?v=_gFB1fkNhXs   \n",
            "3  https://www.youtube.com/watch?v=1WDesu7bUDM   \n",
            "4  https://www.youtube.com/watch?v=bXKWu4GojNI   \n",
            "\n",
            "                                         ingredients  calories   fat  protein  \\\n",
            "0  {'chicken breasts': '2', 'oil': '1 tbsp', 'hot...       416   6.9     41.4   \n",
            "1  {'chicken thighs': '6', 'challots': '16', 'gin...       442   4.8     20.2   \n",
            "2  {'chicken': '1 whole', 'tomato': '1 chopped', ...       541   5.3     23.1   \n",
            "3  {'chicken breast': '1', 'pickle juice': '1/4 c...       858  11.7     61.6   \n",
            "4  {'butter': '1 knob', 'onion': '1 chopped', 'mu...       757  81.1      2.0   \n",
            "\n",
            "   fiber  \n",
            "0   25.3  \n",
            "1   27.4  \n",
            "2   33.1  \n",
            "3   52.7  \n",
            "4    1.7  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/TheMealDB_with_nutrition.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Show basic info before cleaning\n",
        "print(\"Before cleaning:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Strip whitespace and standardize column names\n",
        "df.columns = df.columns.str.strip()\n",
        "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
        "\n",
        "# Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Remove leading/trailing spaces in string columns\n",
        "for col in df.select_dtypes(include='object'):\n",
        "    df[col] = df[col].str.strip()\n",
        "\n",
        "# Handle missing values\n",
        "# Option 1: Drop rows where essential columns (e.g., name, ingredients) are missing\n",
        "essential_columns = ['meal', 'ingredients']  # Update if necessary\n",
        "df = df.dropna(subset=[col for col in essential_columns if col in df.columns])\n",
        "\n",
        "# Option 2 (optional): Fill missing values in non-essential columns\n",
        "df = df.fillna('Unknown')  # Or use specific values depending on column\n",
        "\n",
        "# Normalize text: lowercase for relevant fields\n",
        "for col in ['meal', 'category', 'area', 'ingredients']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].str.lower()\n",
        "\n",
        "# Save cleaned dataset\n",
        "cleaned_path = '/content/TheMealDB_with_nutrition.csv'\n",
        "df.to_csv(cleaned_path, index=False)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n‚úÖ Dataset cleaned and saved to:\", cleaned_path)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptw4AE3XnC0d",
        "outputId": "4e596129-9614-4cf2-ac85-6707b4fa4507"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before cleaning:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 304 entries, 0 to 303\n",
            "Data columns (total 18 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   MealID                  304 non-null    int64  \n",
            " 1   Meal                    304 non-null    object \n",
            " 2   Category                304 non-null    object \n",
            " 3   Area                    304 non-null    object \n",
            " 4   Instructions            304 non-null    object \n",
            " 5   Tags                    183 non-null    object \n",
            " 6   YouTube                 288 non-null    object \n",
            " 7   Ingredients             304 non-null    object \n",
            " 8   EstimatedCalories_kcal  304 non-null    float64\n",
            " 9   EstimatedProtein_g      304 non-null    float64\n",
            " 10  EstimatedFat_g          304 non-null    float64\n",
            " 11  EstimatedCarbs_g        304 non-null    float64\n",
            " 12  calories                304 non-null    float64\n",
            " 13  fat                     304 non-null    float64\n",
            " 14  protein                 304 non-null    float64\n",
            " 15  carbs                   304 non-null    float64\n",
            " 16  sugar                   304 non-null    float64\n",
            " 17  fiber                   304 non-null    float64\n",
            "dtypes: float64(10), int64(1), object(7)\n",
            "memory usage: 42.9+ KB\n",
            "None\n",
            "\n",
            "Missing values per column:\n",
            " MealID                      0\n",
            "Meal                        0\n",
            "Category                    0\n",
            "Area                        0\n",
            "Instructions                0\n",
            "Tags                      121\n",
            "YouTube                    16\n",
            "Ingredients                 0\n",
            "EstimatedCalories_kcal      0\n",
            "EstimatedProtein_g          0\n",
            "EstimatedFat_g              0\n",
            "EstimatedCarbs_g            0\n",
            "calories                    0\n",
            "fat                         0\n",
            "protein                     0\n",
            "carbs                       0\n",
            "sugar                       0\n",
            "fiber                       0\n",
            "dtype: int64\n",
            "\n",
            "‚úÖ Dataset cleaned and saved to: /content/TheMealDB_with_nutrition.csv\n",
            "   mealid                                               meal category  \\\n",
            "0   52874                               beef and mustard pie     beef   \n",
            "1   52878                                beef and oyster pie     beef   \n",
            "2   53071                                         beef asado     beef   \n",
            "3   52997  beef banh mi bowls with sriracha mayo, carrot ...     beef   \n",
            "4   52904                                   beef bourguignon     beef   \n",
            "\n",
            "         area                                       instructions      tags  \\\n",
            "0     british  Preheat the oven to 150C/300F/Gas 2.\\r\\nToss t...  Meat,Pie   \n",
            "1     british  Season the beef cubes with salt and black pepp...       Pie   \n",
            "2    filipino  0.\\tCombine beef, crushed peppercorn, soy sauc...   Unknown   \n",
            "3  vietnamese  Add'l ingredients: mayonnaise, siracha\\r\\n\\r\\n...   Unknown   \n",
            "4      french  Heat a large casserole pan and add 1 tbsp goos...   Unknown   \n",
            "\n",
            "                                       youtube  \\\n",
            "0  https://www.youtube.com/watch?v=nMyBC9staMU   \n",
            "1  https://www.youtube.com/watch?v=ONX74yP6JnI   \n",
            "2  https://www.youtube.com/watch?v=lNlK8DVhXXA   \n",
            "3                                      Unknown   \n",
            "4  https://www.youtube.com/watch?v=SQnr4Z-7rok   \n",
            "\n",
            "                                         ingredients  estimatedcalories_kcal  \\\n",
            "0  {'beef': '1kg', 'plain flour': '2 tbs', 'rapes...                     0.0   \n",
            "1  {'beef': '900g', 'olive oil': '3 tbs', 'shallo...                     0.0   \n",
            "2  {'beef': '1.5kg', 'beef stock concentrate': '1...                     0.0   \n",
            "3  {'rice': 'white', 'onion': '1', 'lime': '1', '...                     0.0   \n",
            "4  {'goose fat': '3 tsp', 'beef shin': '600g', 'b...                     0.0   \n",
            "\n",
            "   estimatedprotein_g  estimatedfat_g  estimatedcarbs_g  calories   fat  \\\n",
            "0                 0.0             0.0               0.0     953.0  92.3   \n",
            "1                 0.0             0.0               0.0    1021.0  92.5   \n",
            "2                 0.0             0.0               0.0     942.0  82.0   \n",
            "3                 0.0             0.0               0.0     360.0   1.1   \n",
            "4                 0.0             0.0               0.0     167.0   0.7   \n",
            "\n",
            "   protein  carbs  sugar  fiber  \n",
            "0     15.9   20.5   10.1    4.5  \n",
            "1     20.3   34.2    2.2    2.1  \n",
            "2     10.2   50.2   10.5    6.2  \n",
            "3     11.1   80.3   10.0    7.0  \n",
            "4      7.3   36.9    3.6    3.3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/all_mealdb_recipes_120+.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Show basic info before cleaning\n",
        "print(\"Before cleaning:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Strip whitespace and standardize column names\n",
        "df.columns = df.columns.str.strip()\n",
        "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
        "\n",
        "# Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Remove leading/trailing spaces in string columns\n",
        "for col in df.select_dtypes(include='object'):\n",
        "    df[col] = df[col].str.strip()\n",
        "\n",
        "# Handle missing values\n",
        "# Option 1: Drop rows where essential columns (e.g., name, ingredients) are missing\n",
        "essential_columns = ['meal', 'ingredients']  # Update if necessary\n",
        "df = df.dropna(subset=[col for col in essential_columns if col in df.columns])\n",
        "\n",
        "# Option 2 (optional): Fill missing values in non-essential columns\n",
        "df = df.fillna('Unknown')  # Or use specific values depending on column\n",
        "\n",
        "# Normalize text: lowercase for relevant fields\n",
        "for col in ['meal', 'category', 'area', 'ingredients']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].str.lower()\n",
        "\n",
        "# Save cleaned dataset\n",
        "cleaned_path = '/content/all_mealdb_recipes_120+.csv'\n",
        "df.to_csv(cleaned_path, index=False)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n‚úÖ Dataset cleaned and saved to:\", cleaned_path)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fPIbESSm_c-",
        "outputId": "cd661e57-b847-40f3-960b-045baaac18a4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before cleaning:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 120 entries, 0 to 119\n",
            "Data columns (total 14 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   MealID        120 non-null    int64  \n",
            " 1   Meal          120 non-null    object \n",
            " 2   Category      120 non-null    object \n",
            " 3   Area          120 non-null    object \n",
            " 4   Instructions  120 non-null    object \n",
            " 5   Tags          72 non-null     object \n",
            " 6   YouTube       111 non-null    object \n",
            " 7   Ingredients   120 non-null    object \n",
            " 8   calories      120 non-null    float64\n",
            " 9   fat           120 non-null    float64\n",
            " 10  protein       120 non-null    float64\n",
            " 11  carbs         120 non-null    float64\n",
            " 12  sugar         120 non-null    float64\n",
            " 13  fiber         120 non-null    float64\n",
            "dtypes: float64(6), int64(1), object(7)\n",
            "memory usage: 13.3+ KB\n",
            "None\n",
            "\n",
            "Missing values per column:\n",
            " MealID           0\n",
            "Meal             0\n",
            "Category         0\n",
            "Area             0\n",
            "Instructions     0\n",
            "Tags            48\n",
            "YouTube          9\n",
            "Ingredients      0\n",
            "calories         0\n",
            "fat              0\n",
            "protein          0\n",
            "carbs            0\n",
            "sugar            0\n",
            "fiber            0\n",
            "dtype: int64\n",
            "\n",
            "‚úÖ Dataset cleaned and saved to: /content/all_mealdb_recipes_120+.csv\n",
            "   mealid                                               meal category  \\\n",
            "0   52874                               beef and mustard pie     beef   \n",
            "1   52878                                beef and oyster pie     beef   \n",
            "2   53071                                         beef asado     beef   \n",
            "3   52997  beef banh mi bowls with sriracha mayo, carrot ...     beef   \n",
            "4   52904                                   beef bourguignon     beef   \n",
            "\n",
            "         area                                       instructions      tags  \\\n",
            "0     british  Preheat the oven to 150C/300F/Gas 2.\\r\\nToss t...  Meat,Pie   \n",
            "1     british  Season the beef cubes with salt and black pepp...       Pie   \n",
            "2    filipino  0.\\tCombine beef, crushed peppercorn, soy sauc...   Unknown   \n",
            "3  vietnamese  Add'l ingredients: mayonnaise, siracha\\r\\n\\r\\n...   Unknown   \n",
            "4      french  Heat a large casserole pan and add 1 tbsp goos...   Unknown   \n",
            "\n",
            "                                       youtube  \\\n",
            "0  https://www.youtube.com/watch?v=nMyBC9staMU   \n",
            "1  https://www.youtube.com/watch?v=ONX74yP6JnI   \n",
            "2  https://www.youtube.com/watch?v=lNlK8DVhXXA   \n",
            "3                                      Unknown   \n",
            "4  https://www.youtube.com/watch?v=SQnr4Z-7rok   \n",
            "\n",
            "                                         ingredients  calories   fat  protein  \\\n",
            "0  {'beef': '1kg', 'plain flour': '2 tbs', 'rapes...     953.0  92.3     15.9   \n",
            "1  {'beef': '900g', 'olive oil': '3 tbs', 'shallo...    1021.0  92.5     20.3   \n",
            "2  {'beef': '1.5kg', 'beef stock concentrate': '1...     942.0  82.0     10.2   \n",
            "3  {'rice': 'white', 'onion': '1', 'lime': '1', '...     360.0   1.1     11.1   \n",
            "4  {'goose fat': '3 tsp', 'beef shin': '600g', 'b...     167.0   0.7      7.3   \n",
            "\n",
            "   carbs  sugar  fiber  \n",
            "0   20.5   10.1    4.5  \n",
            "1   34.2    2.2    2.1  \n",
            "2   50.2   10.5    6.2  \n",
            "3   80.3   10.0    7.0  \n",
            "4   36.9    3.6    3.3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/themealdb_500_recipes.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Show basic info before cleaning\n",
        "print(\"Before cleaning:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Strip whitespace and standardize column names\n",
        "df.columns = df.columns.str.strip()\n",
        "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
        "\n",
        "# Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Remove leading/trailing spaces in string columns\n",
        "for col in df.select_dtypes(include='object'):\n",
        "    df[col] = df[col].str.strip()\n",
        "\n",
        "# Handle missing values\n",
        "# Option 1: Drop rows where essential columns (e.g., name, ingredients) are missing\n",
        "essential_columns = ['meal', 'ingredients']  # Update if necessary\n",
        "df = df.dropna(subset=[col for col in essential_columns if col in df.columns])\n",
        "\n",
        "# Option 2 (optional): Fill missing values in non-essential columns\n",
        "df = df.fillna('Unknown')  # Or use specific values depending on column\n",
        "\n",
        "# Normalize text: lowercase for relevant fields\n",
        "for col in ['meal', 'category', 'area', 'ingredients']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].str.lower()\n",
        "\n",
        "# Save cleaned dataset\n",
        "cleaned_path = '/content/themealdb_500_recipes.csv'\n",
        "df.to_csv(cleaned_path, index=False)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n‚úÖ Dataset cleaned and saved to:\", cleaned_path)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZtMGBQgoDPY",
        "outputId": "be168a7c-9650-48dd-bdc7-6ce70084f579"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before cleaning:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 302 entries, 0 to 301\n",
            "Data columns (total 12 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   MealID         302 non-null    int64  \n",
            " 1   Meal           302 non-null    object \n",
            " 2   Category       302 non-null    object \n",
            " 3   Area           302 non-null    object \n",
            " 4   Instructions   302 non-null    object \n",
            " 5   Ingredients    302 non-null    object \n",
            " 6   Calories       302 non-null    int64  \n",
            " 7   Fat            302 non-null    float64\n",
            " 8   Protein        302 non-null    float64\n",
            " 9   Sugar          302 non-null    float64\n",
            " 10  Fiber          302 non-null    float64\n",
            " 11  Carbohydrates  302 non-null    float64\n",
            "dtypes: float64(5), int64(2), object(5)\n",
            "memory usage: 28.4+ KB\n",
            "None\n",
            "\n",
            "Missing values per column:\n",
            " MealID           0\n",
            "Meal             0\n",
            "Category         0\n",
            "Area             0\n",
            "Instructions     0\n",
            "Ingredients      0\n",
            "Calories         0\n",
            "Fat              0\n",
            "Protein          0\n",
            "Sugar            0\n",
            "Fiber            0\n",
            "Carbohydrates    0\n",
            "dtype: int64\n",
            "\n",
            "‚úÖ Dataset cleaned and saved to: /content/themealdb_500_recipes.csv\n",
            "   mealid                                meal    category      area  \\\n",
            "0   52917        white chocolate creme brulee     dessert    french   \n",
            "1   53074  grilled eggplant with coconut milk  vegetarian  filipino   \n",
            "2   53006                            moussaka        beef     greek   \n",
            "3   53027                             koshari  vegetarian  egyptian   \n",
            "4   52877                 lamb and potato pie        lamb   british   \n",
            "\n",
            "                                        instructions  \\\n",
            "0  Heat the cream, chocolate and vanilla pod in a...   \n",
            "1  .  Prepare the eggplants for grilling by prick...   \n",
            "2  Heat the grill to high. Brown the beef in a de...   \n",
            "3  Cook the lentils. Bring lentils and 4 cups of ...   \n",
            "4  Dust the meat with flour to lightly coat.\\r\\nH...   \n",
            "\n",
            "                                         ingredients  calories   fat  protein  \\\n",
            "0  double cream, white chocolate chips, vanilla, ...       155  11.0     13.0   \n",
            "1  egg plants, coconut milk, lemon juice, salt, r...       237  12.1     17.5   \n",
            "2  beef, aubergine, greek yogurt, egg, parmesan, ...       191  11.4     14.8   \n",
            "3  brown lentils, rice, coriander, macaroni, chic...       170   0.4      3.8   \n",
            "4  lamb shoulder, flour, vegetable oil, onion, ca...       236  11.3     15.0   \n",
            "\n",
            "   sugar  fiber  carbohydrates  \n",
            "0    1.1    0.0            1.1  \n",
            "1   10.3    1.7           15.4  \n",
            "2    6.3    2.4            8.9  \n",
            "3    4.3    2.1           37.3  \n",
            "4   10.0    4.5           20.4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV files\n",
        "df1 = pd.read_csv('/content/TheMealDB_with_nutrition.csv')\n",
        "df2 = pd.read_csv('/content/all_mealdb_recipes_120+.csv')\n",
        "df3 = pd.read_csv('/content/themealdb_500_recipes.csv')\n",
        "df4 = pd.read_csv('/content/themealdb_recipes.csv')\n",
        "\n",
        "# Concatenate all dataframes\n",
        "merged_df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
        "\n",
        "\n",
        "# merged_df = merged_df.drop_duplicates(subset='idMeal')\n",
        "\n",
        "# Save the merged dataframe to a new CSV\n",
        "merged_df.to_csv('/content/merged dataset.csv', index=False)\n",
        "\n",
        "print(\"Merge complete. Saved as 'merged_mealdb_recipes.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsglp4oOovWt",
        "outputId": "5d3e7706-8ce9-4b0a-f466-8ae51644a406"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merge complete. Saved as 'merged_mealdb_recipes.csv'\n"
          ]
        }
      ]
    }
  ]
}