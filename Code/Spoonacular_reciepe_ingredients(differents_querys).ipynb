{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB-PdtNCtd6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c46012c0-ab72-4220-93d9-6c2f3e20b492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 10)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 20)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 30)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 40)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 50)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 60)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 70)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 80)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 90)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 100)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 110)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 120)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 130)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 140)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 150)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 160)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 170)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 180)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 190)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 200)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 210)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 220)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 230)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 240)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 250)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 260)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 270)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 280)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 290)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 300)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 310)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 320)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 330)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 340)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 350)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 360)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 370)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 380)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 390)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 400)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 410)\n",
            "✅ Saved 9 recipes from query 'vegetarian' (Total: 419)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 429)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 439)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 449)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 459)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 469)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 479)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 489)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 499)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 509)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 519)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 529)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 539)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 549)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 559)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 569)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 579)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 589)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 599)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 609)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 619)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 629)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 639)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 649)\n",
            "✅ Saved 9 recipes from query 'vegetarian' (Total: 658)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 668)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 678)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 688)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 698)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 708)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 718)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 728)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 738)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 748)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 758)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 768)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 778)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 788)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 798)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 808)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 818)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 828)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 838)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 848)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 858)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 868)\n",
            "✅ Saved 9 recipes from query 'vegetarian' (Total: 877)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 887)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 897)\n",
            "✅ Saved 10 recipes from query 'vegetarian' (Total: 907)\n",
            "⚠️ No new recipes found at offset 910 for query 'vegetarian'\n",
            "⚠️ No new recipes found at offset 920 for query 'vegetarian'\n",
            "⚠️ No new recipes found at offset 930 for query 'vegetarian'\n",
            "❌ Error 402 at offset 940 with query 'vegetarian': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "❌ Error 402 at offset 0 with query 'vegetarian curry': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "❌ Error 402 at offset 0 with query 'vegetarian pasta': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "❌ Error 402 at offset 0 with query 'vegetarian soup': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "❌ Error 402 at offset 0 with query 'vegetarian salad': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "❌ Error 402 at offset 0 with query 'vegetarian sandwich': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "❌ Error 402 at offset 0 with query 'grilled vegetables': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "❌ Error 402 at offset 0 with query 'tofu': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "❌ Error 402 at offset 0 with query 'paneer': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "❌ Error 402 at offset 0 with query 'vegan stir fry': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "🎉 Finished. Total unique recipes collected: 907\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "API_KEY = \"6c6716d9526042f3854c309efdcdf20b\"\n",
        "OUTPUT_FILE = \"vegetarian_recipes.csv\"\n",
        "BATCH_SIZE = 10\n",
        "RECIPES_TO_COLLECT = 5000\n",
        "\n",
        "# Vegetarian recipe subqueries\n",
        "query_variants = [\n",
        "    \"vegetarian\", \"vegetarian curry\", \"vegetarian pasta\", \"vegetarian soup\",\n",
        "    \"vegetarian salad\", \"vegetarian sandwich\", \"grilled vegetables\",\n",
        "    \"tofu\", \"paneer\", \"vegan stir fry\"\n",
        "]\n",
        "\n",
        "# Track collected recipes to prevent duplication\n",
        "collected_titles = set()\n",
        "total_collected = 0\n",
        "\n",
        "# Initialize CSV file if it doesn't exist\n",
        "if not os.path.exists(OUTPUT_FILE):\n",
        "    pd.DataFrame(columns=[\"recipe_name\", \"ingredients\", \"calories\", \"protein\", \"fat\",\n",
        "                          \"carbohydrates\", \"fiber\", \"sugar\"]).to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "# Loop through queries and offsets\n",
        "for query in query_variants:\n",
        "    for offset in range(0, 1000, BATCH_SIZE):  # Max 1000 per query\n",
        "        if total_collected >= RECIPES_TO_COLLECT:\n",
        "            break\n",
        "\n",
        "        url = \"https://api.spoonacular.com/recipes/complexSearch\"\n",
        "        params = {\n",
        "            \"query\": query,\n",
        "            \"number\": BATCH_SIZE,\n",
        "            \"offset\": offset,\n",
        "            \"addRecipeNutrition\": True,\n",
        "            \"apiKey\": API_KEY\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code != 200:\n",
        "                print(f\"❌ Error {response.status_code} at offset {offset} with query '{query}': {response.text}\")\n",
        "                break\n",
        "\n",
        "            data = response.json()\n",
        "            batch_recipes = []\n",
        "\n",
        "            for recipe in data.get(\"results\", []):\n",
        "                title = recipe.get(\"title\", \"\")\n",
        "                if title in collected_titles:\n",
        "                    continue\n",
        "\n",
        "                collected_titles.add(title)\n",
        "\n",
        "                ingredients = [i['name'] for i in recipe.get(\"nutrition\", {}).get(\"ingredients\", [])]\n",
        "                nutrients = {n[\"name\"]: n[\"amount\"] for n in recipe.get(\"nutrition\", {}).get(\"nutrients\", [])}\n",
        "\n",
        "                batch_recipes.append({\n",
        "                    \"recipe_name\": title,\n",
        "                    \"ingredients\": ingredients,\n",
        "                    \"calories\": nutrients.get(\"Calories\"),\n",
        "                    \"protein\": nutrients.get(\"Protein\"),\n",
        "                    \"fat\": nutrients.get(\"Fat\"),\n",
        "                    \"carbohydrates\": nutrients.get(\"Carbohydrates\"),\n",
        "                    \"fiber\": nutrients.get(\"Fiber\"),\n",
        "                    \"sugar\": nutrients.get(\"Sugar\")\n",
        "                })\n",
        "\n",
        "            if batch_recipes:\n",
        "                df = pd.DataFrame(batch_recipes)\n",
        "                df.to_csv(OUTPUT_FILE, mode='a', header=False, index=False)\n",
        "                total_collected += len(batch_recipes)\n",
        "                print(f\"✅ Saved {len(batch_recipes)} recipes from query '{query}' (Total: {total_collected})\")\n",
        "            else:\n",
        "                print(f\"⚠️ No new recipes found at offset {offset} for query '{query}'\")\n",
        "\n",
        "            time.sleep(1)  # Respect API limits\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Exception for query '{query}' at offset {offset}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total_collected >= RECIPES_TO_COLLECT:\n",
        "        break\n",
        "\n",
        "print(f\"🎉 Finished. Total unique recipes collected: {total_collected}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "API_KEY = \"6c6716d9526042f3854c309efdcdf20b\"\n",
        "OUTPUT_FILE = \"dessert_recipes.csv\"\n",
        "BATCH_SIZE = 10\n",
        "RECIPES_TO_COLLECT = 5000\n",
        "\n",
        "# Dessert recipe subqueries\n",
        "query_variants = [\n",
        "    \"chocolate mousse\", \"apple pie\", \"banana pancakes\", \"cheesecake\", \"fruit salad\",\n",
        "    \"brownies\", \"cupcakes\", \"ice cream\", \"pudding\", \"cookies\",\n",
        "    \"tiramisu\", \"donuts\", \"muffins\", \"trifle\", \"cobbler\"\n",
        "]\n",
        "\n",
        "# Track collected recipes to prevent duplication\n",
        "collected_titles = set()\n",
        "total_collected = 0\n",
        "\n",
        "# Initialize CSV file if it doesn't exist\n",
        "if not os.path.exists(OUTPUT_FILE):\n",
        "    pd.DataFrame(columns=[\"recipe_name\", \"ingredients\", \"calories\", \"protein\", \"fat\",\n",
        "                          \"carbohydrates\", \"fiber\", \"sugar\"]).to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "# Loop through queries and offsets\n",
        "for query in query_variants:\n",
        "    for offset in range(0, 1000, BATCH_SIZE):  # Max 1000 per query\n",
        "        if total_collected >= RECIPES_TO_COLLECT:\n",
        "            break\n",
        "\n",
        "        url = \"https://api.spoonacular.com/recipes/complexSearch\"\n",
        "        params = {\n",
        "            \"query\": query,\n",
        "            \"number\": BATCH_SIZE,\n",
        "            \"offset\": offset,\n",
        "            \"addRecipeNutrition\": True,\n",
        "            \"apiKey\": API_KEY\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code != 200:\n",
        "                print(f\"❌ Error {response.status_code} at offset {offset} with query '{query}': {response.text}\")\n",
        "                break\n",
        "\n",
        "            data = response.json()\n",
        "            batch_recipes = []\n",
        "\n",
        "            for recipe in data.get(\"results\", []):\n",
        "                title = recipe.get(\"title\", \"\")\n",
        "                if title in collected_titles:\n",
        "                    continue\n",
        "\n",
        "                collected_titles.add(title)\n",
        "\n",
        "                ingredients = [i['name'] for i in recipe.get(\"nutrition\", {}).get(\"ingredients\", [])]\n",
        "                nutrients = {n[\"name\"]: n[\"amount\"] for n in recipe.get(\"nutrition\", {}).get(\"nutrients\", [])}\n",
        "\n",
        "                batch_recipes.append({\n",
        "                    \"recipe_name\": title,\n",
        "                    \"ingredients\": ingredients,\n",
        "                    \"calories\": nutrients.get(\"Calories\"),\n",
        "                    \"protein\": nutrients.get(\"Protein\"),\n",
        "                    \"fat\": nutrients.get(\"Fat\"),\n",
        "                    \"carbohydrates\": nutrients.get(\"Carbohydrates\"),\n",
        "                    \"fiber\": nutrients.get(\"Fiber\"),\n",
        "                    \"sugar\": nutrients.get(\"Sugar\")\n",
        "                })\n",
        "\n",
        "            if batch_recipes:\n",
        "                df = pd.DataFrame(batch_recipes)\n",
        "                df.to_csv(OUTPUT_FILE, mode='a', header=False, index=False)\n",
        "                total_collected += len(batch_recipes)\n",
        "                print(f\"✅ Saved {len(batch_recipes)} recipes from query '{query}' (Total: {total_collected})\")\n",
        "            else:\n",
        "                print(f\"⚠️ No new recipes found at offset {offset} for query '{query}'\")\n",
        "\n",
        "            time.sleep(1)  # Respect API limits\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Exception for query '{query}' at offset {offset}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total_collected >= RECIPES_TO_COLLECT:\n",
        "        break\n",
        "\n",
        "print(f\"🎉 Finished. Total unique dessert recipes collected: {total_collected}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "h3jlUY9_r9b6",
        "outputId": "4236a21a-3f15-4e4c-8660-b0de350beb4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 6 recipes from query 'chocolate mousse' (Total: 6)\n",
            "⚠️ No new recipes found at offset 10 for query 'chocolate mousse'\n",
            "⚠️ No new recipes found at offset 20 for query 'chocolate mousse'\n",
            "⚠️ No new recipes found at offset 30 for query 'chocolate mousse'\n",
            "⚠️ No new recipes found at offset 40 for query 'chocolate mousse'\n",
            "⚠️ No new recipes found at offset 50 for query 'chocolate mousse'\n",
            "⚠️ No new recipes found at offset 60 for query 'chocolate mousse'\n",
            "⚠️ No new recipes found at offset 70 for query 'chocolate mousse'\n",
            "⚠️ No new recipes found at offset 80 for query 'chocolate mousse'\n",
            "⚠️ No new recipes found at offset 90 for query 'chocolate mousse'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-61c8a7f9d6c6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"❌ Error {response.status_code} at offset {offset} with query '{query}': {response.text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "API_KEY = \"6c6716d9526042f3854c309efdcdf20b\"\n",
        "OUTPUT_FILE = \"seafood_recipes.csv\"\n",
        "BATCH_SIZE = 10\n",
        "RECIPES_TO_COLLECT = 5000\n",
        "\n",
        "# Seafood recipe subqueries\n",
        "query_variants = [\n",
        "    \"fish\"\n",
        "]\n",
        "\n",
        "# Track collected recipes to prevent duplication\n",
        "collected_titles = set()\n",
        "total_collected = 0\n",
        "\n",
        "# Initialize CSV file if it doesn't exist\n",
        "if not os.path.exists(OUTPUT_FILE):\n",
        "    pd.DataFrame(columns=[\"recipe_name\", \"ingredients\", \"calories\", \"protein\", \"fat\",\n",
        "                          \"carbohydrates\", \"fiber\", \"sugar\"]).to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "# Loop through queries and offsets\n",
        "for query in query_variants:\n",
        "    for offset in range(0, 1000, BATCH_SIZE):  # Max 1000 per query\n",
        "        if total_collected >= RECIPES_TO_COLLECT:\n",
        "            break\n",
        "\n",
        "        url = \"https://api.spoonacular.com/recipes/complexSearch\"\n",
        "        params = {\n",
        "            \"query\": query,\n",
        "            \"number\": BATCH_SIZE,\n",
        "            \"offset\": offset,\n",
        "            \"addRecipeNutrition\": True,\n",
        "            \"apiKey\": API_KEY\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code != 200:\n",
        "                print(f\"❌ Error {response.status_code} at offset {offset} with query '{query}': {response.text}\")\n",
        "                break\n",
        "\n",
        "            data = response.json()\n",
        "            batch_recipes = []\n",
        "\n",
        "            for recipe in data.get(\"results\", []):\n",
        "                title = recipe.get(\"title\", \"\")\n",
        "                if title in collected_titles:\n",
        "                    continue\n",
        "\n",
        "                collected_titles.add(title)\n",
        "\n",
        "                ingredients = [i['name'] for i in recipe.get(\"nutrition\", {}).get(\"ingredients\", [])]\n",
        "                nutrients = {n[\"name\"]: n[\"amount\"] for n in recipe.get(\"nutrition\", {}).get(\"nutrients\", [])}\n",
        "\n",
        "                batch_recipes.append({\n",
        "                    \"recipe_name\": title,\n",
        "                    \"ingredients\": ingredients,\n",
        "                    \"calories\": nutrients.get(\"Calories\"),\n",
        "                    \"protein\": nutrients.get(\"Protein\"),\n",
        "                    \"fat\": nutrients.get(\"Fat\"),\n",
        "                    \"carbohydrates\": nutrients.get(\"Carbohydrates\"),\n",
        "                    \"fiber\": nutrients.get(\"Fiber\"),\n",
        "                    \"sugar\": nutrients.get(\"Sugar\")\n",
        "                })\n",
        "\n",
        "            if batch_recipes:\n",
        "                df = pd.DataFrame(batch_recipes)\n",
        "                df.to_csv(OUTPUT_FILE, mode='a', header=False, index=False)\n",
        "                total_collected += len(batch_recipes)\n",
        "                print(f\"✅ Saved {len(batch_recipes)} recipes from query '{query}' (Total: {total_collected})\")\n",
        "            else:\n",
        "                print(f\"⚠️ No new recipes found at offset {offset} for query '{query}'\")\n",
        "\n",
        "            time.sleep(1)  # Respect API limits\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Exception for query '{query}' at offset {offset}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total_collected >= RECIPES_TO_COLLECT:\n",
        "        break\n",
        "\n",
        "print(f\"🎉 Finished. Total unique seafood recipes collected: {total_collected}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XMC36IvTsWvp",
        "outputId": "81686a55-c6c7-498f-9e49-17504b926b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 10 recipes from query 'fish' (Total: 10)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 20)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 30)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 40)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 50)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 60)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 70)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 80)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 90)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 100)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 110)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 120)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 130)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 140)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 150)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 160)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 170)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 180)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 190)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 200)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 210)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 220)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 230)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 240)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 250)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 260)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 270)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 280)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 290)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 300)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 310)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 320)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 330)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 340)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 350)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 360)\n",
            "✅ Saved 10 recipes from query 'fish' (Total: 370)\n",
            "✅ Saved 8 recipes from query 'fish' (Total: 378)\n",
            "⚠️ No new recipes found at offset 380 for query 'fish'\n",
            "⚠️ No new recipes found at offset 390 for query 'fish'\n",
            "⚠️ No new recipes found at offset 400 for query 'fish'\n",
            "⚠️ No new recipes found at offset 410 for query 'fish'\n",
            "⚠️ No new recipes found at offset 420 for query 'fish'\n",
            "⚠️ No new recipes found at offset 430 for query 'fish'\n",
            "⚠️ No new recipes found at offset 440 for query 'fish'\n",
            "⚠️ No new recipes found at offset 450 for query 'fish'\n",
            "⚠️ No new recipes found at offset 460 for query 'fish'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b01a4b4247e2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"❌ Error {response.status_code} at offset {offset} with query '{query}': {response.text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "API_KEY = \"6c6716d9526042f3854c309efdcdf20b\"\n",
        "OUTPUT_FILE = \"italian_recipes.csv\"\n",
        "BATCH_SIZE = 10\n",
        "RECIPES_TO_COLLECT = 5000\n",
        "\n",
        "# Seafood recipe subqueries\n",
        "query_variants = [\n",
        "    \"italian\"\n",
        "]\n",
        "\n",
        "# Track collected recipes to prevent duplication\n",
        "collected_titles = set()\n",
        "total_collected = 0\n",
        "\n",
        "# Initialize CSV file if it doesn't exist\n",
        "if not os.path.exists(OUTPUT_FILE):\n",
        "    pd.DataFrame(columns=[\"recipe_name\", \"ingredients\", \"calories\", \"protein\", \"fat\",\n",
        "                          \"carbohydrates\", \"fiber\", \"sugar\"]).to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "# Loop through queries and offsets\n",
        "for query in query_variants:\n",
        "    for offset in range(0, 1000, BATCH_SIZE):  # Max 1000 per query\n",
        "        if total_collected >= RECIPES_TO_COLLECT:\n",
        "            break\n",
        "\n",
        "        url = \"https://api.spoonacular.com/recipes/complexSearch\"\n",
        "        params = {\n",
        "            \"query\": query,\n",
        "            \"number\": BATCH_SIZE,\n",
        "            \"offset\": offset,\n",
        "            \"addRecipeNutrition\": True,\n",
        "            \"apiKey\": API_KEY\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code != 200:\n",
        "                print(f\"❌ Error {response.status_code} at offset {offset} with query '{query}': {response.text}\")\n",
        "                break\n",
        "\n",
        "            data = response.json()\n",
        "            batch_recipes = []\n",
        "\n",
        "            for recipe in data.get(\"results\", []):\n",
        "                title = recipe.get(\"title\", \"\")\n",
        "                if title in collected_titles:\n",
        "                    continue\n",
        "\n",
        "                collected_titles.add(title)\n",
        "\n",
        "                ingredients = [i['name'] for i in recipe.get(\"nutrition\", {}).get(\"ingredients\", [])]\n",
        "                nutrients = {n[\"name\"]: n[\"amount\"] for n in recipe.get(\"nutrition\", {}).get(\"nutrients\", [])}\n",
        "\n",
        "                batch_recipes.append({\n",
        "                    \"recipe_name\": title,\n",
        "                    \"ingredients\": ingredients,\n",
        "                    \"calories\": nutrients.get(\"Calories\"),\n",
        "                    \"protein\": nutrients.get(\"Protein\"),\n",
        "                    \"fat\": nutrients.get(\"Fat\"),\n",
        "                    \"carbohydrates\": nutrients.get(\"Carbohydrates\"),\n",
        "                    \"fiber\": nutrients.get(\"Fiber\"),\n",
        "                    \"sugar\": nutrients.get(\"Sugar\")\n",
        "                })\n",
        "\n",
        "            if batch_recipes:\n",
        "                df = pd.DataFrame(batch_recipes)\n",
        "                df.to_csv(OUTPUT_FILE, mode='a', header=False, index=False)\n",
        "                total_collected += len(batch_recipes)\n",
        "                print(f\"✅ Saved {len(batch_recipes)} recipes from query '{query}' (Total: {total_collected})\")\n",
        "            else:\n",
        "                print(f\"⚠️ No new recipes found at offset {offset} for query '{query}'\")\n",
        "\n",
        "            time.sleep(1)  # Respect API limits\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Exception for query '{query}' at offset {offset}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total_collected >= RECIPES_TO_COLLECT:\n",
        "        break\n",
        "\n",
        "print(f\"🎉 Finished. Total unique seafood recipes collected: {total_collected}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHOHVa5ktp3o",
        "outputId": "1c9a0967-ca79-4332-8f71-5ee1edd3da33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 10 recipes from query 'italian' (Total: 10)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 20)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 30)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 40)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 50)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 60)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 70)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 80)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 90)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 100)\n",
            "✅ Saved 9 recipes from query 'italian' (Total: 109)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 119)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 129)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 139)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 149)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 159)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 169)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 179)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 189)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 199)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 209)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 219)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 229)\n",
            "✅ Saved 10 recipes from query 'italian' (Total: 239)\n",
            "❌ Error 402 at offset 240 with query 'italian': {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "🎉 Finished. Total unique seafood recipes collected: 239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "API_KEY = \"6c6716d9526042f3854c309efdcdf20b\"\n",
        "OUTPUT_FILE = \"italian_recipes.csv\"\n",
        "BATCH_SIZE = 10\n",
        "RECIPES_TO_COLLECT = 5000\n",
        "\n",
        "query_variants = [\n",
        "    \"italian\"\n",
        "]\n",
        "\n",
        "collected_titles = set()\n",
        "total_collected = 0\n",
        "\n",
        "if not os.path.exists(OUTPUT_FILE):\n",
        "    pd.DataFrame(columns=[\"recipe_name\", \"ingredients\", \"calories\", \"protein\", \"fat\",\n",
        "                          \"carbohydrates\", \"fiber\", \"sugar\"]).to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "for query in query_variants:\n",
        "    for offset in range(0, 1000, BATCH_SIZE):\n",
        "        if total_collected >= RECIPES_TO_COLLECT:\n",
        "            break\n",
        "\n",
        "        search_url = \"https://api.spoonacular.com/recipes/complexSearch\"\n",
        "        search_params = {\n",
        "            \"query\": query,\n",
        "            \"number\": BATCH_SIZE,\n",
        "            \"offset\": offset,\n",
        "            \"apiKey\": API_KEY\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            search_response = requests.get(search_url, params=search_params)\n",
        "            if search_response.status_code != 200:\n",
        "                print(f\"❌ Error {search_response.status_code} at offset {offset}: {search_response.text}\")\n",
        "                break\n",
        "\n",
        "            recipes = search_response.json().get(\"results\", [])\n",
        "            batch_recipes = []\n",
        "\n",
        "            for recipe in recipes:\n",
        "                recipe_id = recipe[\"id\"]\n",
        "                title = recipe.get(\"title\", \"\")\n",
        "                if title in collected_titles:\n",
        "                    continue\n",
        "\n",
        "                # Get full recipe info\n",
        "                info_url = f\"https://api.spoonacular.com/recipes/{recipe_id}/information\"\n",
        "                info_params = {\n",
        "                    \"includeNutrition\": True,\n",
        "                    \"apiKey\": API_KEY\n",
        "                }\n",
        "\n",
        "                info_response = requests.get(info_url, params=info_params)\n",
        "                if info_response.status_code != 200:\n",
        "                    print(f\"⚠️ Failed to get info for recipe {recipe_id}: {info_response.text}\")\n",
        "                    continue\n",
        "\n",
        "                info = info_response.json()\n",
        "\n",
        "                # Extract ingredients\n",
        "                ingredients = [ing[\"original\"] for ing in info.get(\"extendedIngredients\", [])]\n",
        "\n",
        "                # Extract nutrients\n",
        "                nutrients = {}\n",
        "                for n in info.get(\"nutrition\", {}).get(\"nutrients\", []):\n",
        "                    nutrients[n[\"name\"]] = n[\"amount\"]\n",
        "\n",
        "                batch_recipes.append({\n",
        "                    \"recipe_name\": title,\n",
        "                    \"ingredients\": ingredients,\n",
        "                    \"calories\": nutrients.get(\"Calories\"),\n",
        "                    \"protein\": nutrients.get(\"Protein\"),\n",
        "                    \"fat\": nutrients.get(\"Fat\"),\n",
        "                    \"carbohydrates\": nutrients.get(\"Carbohydrates\"),\n",
        "                    \"fiber\": nutrients.get(\"Fiber\"),\n",
        "                    \"sugar\": nutrients.get(\"Sugar\")\n",
        "                })\n",
        "\n",
        "                collected_titles.add(title)\n",
        "                total_collected += 1\n",
        "                time.sleep(1)  # avoid rate limit\n",
        "\n",
        "            if batch_recipes:\n",
        "                df = pd.DataFrame(batch_recipes)\n",
        "                df.to_csv(OUTPUT_FILE, mode='a', header=False, index=False)\n",
        "                print(f\"✅ Saved {len(batch_recipes)} recipes (Total: {total_collected})\")\n",
        "            else:\n",
        "                print(f\"⚠️ No new recipes found at offset {offset} for query '{query}'\")\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Exception at offset {offset}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if total_collected >= RECIPES_TO_COLLECT:\n",
        "        break\n",
        "\n",
        "print(f\"🎉 Finished. Total unique Italian recipes collected: {total_collected}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM0Qlbg4Hd0W",
        "outputId": "60adb670-7d21-49b0-c8af-68f193441b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 10 recipes (Total: 10)\n",
            "✅ Saved 10 recipes (Total: 20)\n",
            "✅ Saved 10 recipes (Total: 30)\n",
            "✅ Saved 10 recipes (Total: 40)\n",
            "✅ Saved 10 recipes (Total: 50)\n",
            "✅ Saved 10 recipes (Total: 60)\n",
            "✅ Saved 10 recipes (Total: 70)\n",
            "✅ Saved 10 recipes (Total: 80)\n",
            "✅ Saved 10 recipes (Total: 90)\n",
            "✅ Saved 10 recipes (Total: 100)\n",
            "✅ Saved 9 recipes (Total: 109)\n",
            "✅ Saved 10 recipes (Total: 119)\n",
            "⚠️ Failed to get info for recipe 650700: {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "⚠️ Failed to get info for recipe 654005: {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "⚠️ Failed to get info for recipe 648660: {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "⚠️ Failed to get info for recipe 1096086: {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "⚠️ Failed to get info for recipe 634891: {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "✅ Saved 5 recipes (Total: 124)\n",
            "❌ Error 402 at offset 130: {\"status\":\"failure\", \"code\":402,\"message\":\"Your daily points limit of 150 has been reached. Please upgrade your plan to continue using the API.\"}\n",
            "🎉 Finished. Total unique Italian recipes collected: 124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "\n",
        "API_KEY = '6c6716d9526042f3854c309efdcdf20b'\n",
        "CSV_FILE = 'recipes_data.csv'\n",
        "TOTAL_RECIPES = 20000\n",
        "BATCH_SIZE = 100  # Max allowed per request\n",
        "\n",
        "def get_recipe_batch(offset):\n",
        "    url = f'https://api.spoonacular.com/recipes/complexSearch'\n",
        "    params = {\n",
        "        'apiKey': API_KEY,\n",
        "        'number': BATCH_SIZE,\n",
        "        'offset': offset,\n",
        "        'addRecipeNutrition': True\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed at offset {offset}: {response.status_code}\")\n",
        "        return []\n",
        "    return response.json().get('results', [])\n",
        "\n",
        "def extract_recipe_info(recipe):\n",
        "    ingredients = ', '.join([ing['name'] for ing in recipe.get('nutrition', {}).get('ingredients', [])])\n",
        "    nutrients = {nutrient['name']: nutrient['amount'] for nutrient in recipe.get('nutrition', {}).get('nutrients', [])}\n",
        "    return [\n",
        "        recipe.get('id'),\n",
        "        recipe.get('title'),\n",
        "        ingredients,\n",
        "        nutrients.get('Calories', ''),\n",
        "        nutrients.get('Protein', ''),\n",
        "        nutrients.get('Fat', ''),\n",
        "        nutrients.get('Carbohydrates', '')\n",
        "    ]\n",
        "\n",
        "def save_recipes_to_csv():\n",
        "    with open(CSV_FILE, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['ID', 'Title', 'Ingredients', 'Calories', 'Protein', 'Fat', 'Carbohydrates'])\n",
        "\n",
        "        for offset in range(0, TOTAL_RECIPES, BATCH_SIZE):\n",
        "            print(f\"Fetching recipes {offset + 1} to {offset + BATCH_SIZE}\")\n",
        "            batch = get_recipe_batch(offset)\n",
        "            if not batch:\n",
        "                print(\"No more data returned. Possibly hit limit.\")\n",
        "                break\n",
        "            for recipe in batch:\n",
        "                writer.writerow(extract_recipe_info(recipe))\n",
        "            time.sleep(6)  # To respect rate limits\n",
        "\n",
        "    print(f\"Saved recipes to {CSV_FILE}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    save_recipes_to_csv()\n"
      ],
      "metadata": {
        "id": "PN1CQuAmDGkB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "c2be6ad5-cf43-4798-a4a6-650d045824b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching recipes 1 to 100\n",
            "Fetching recipes 101 to 200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-33dd8db86f3b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0msave_recipes_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-33dd8db86f3b>\u001b[0m in \u001b[0;36msave_recipes_to_csv\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrecipe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_recipe_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# To respect rate limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved recipes to {CSV_FILE}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "\n",
        "API_KEY = '6c6716d9526042f3854c309efdcdf20b'\n",
        "CSV_FILE = 'recipes_data_2.csv'  # Save to a new file\n",
        "TOTAL_RECIPES = 20000\n",
        "BATCH_SIZE = 100\n",
        "START_OFFSET = 20000  # Start from 20,001st recipe\n",
        "\n",
        "def get_recipe_batch(offset):\n",
        "    url = 'https://api.spoonacular.com/recipes/complexSearch'\n",
        "    params = {\n",
        "        'apiKey': API_KEY,\n",
        "        'number': BATCH_SIZE,\n",
        "        'offset': offset,\n",
        "        'addRecipeNutrition': True\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed at offset {offset}: {response.status_code}\")\n",
        "        return []\n",
        "    return response.json().get('results', [])\n",
        "\n",
        "def extract_recipe_info(recipe):\n",
        "    ingredients = ', '.join([ing['name'] for ing in recipe.get('nutrition', {}).get('ingredients', [])])\n",
        "    nutrients = {nutrient['name']: nutrient['amount'] for nutrient in recipe.get('nutrition', {}).get('nutrients', [])}\n",
        "    return [\n",
        "        recipe.get('id'),\n",
        "        recipe.get('title'),\n",
        "        ingredients,\n",
        "        nutrients.get('Calories', ''),\n",
        "        nutrients.get('Protein', ''),\n",
        "        nutrients.get('Fat', ''),\n",
        "        nutrients.get('Carbohydrates', '')\n",
        "    ]\n",
        "\n",
        "def save_recipes_to_csv():\n",
        "    with open(CSV_FILE, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['ID', 'Title', 'Ingredients', 'Calories', 'Protein', 'Fat', 'Carbohydrates'])\n",
        "\n",
        "        for offset in range(START_OFFSET, START_OFFSET + TOTAL_RECIPES, BATCH_SIZE):\n",
        "            print(f\"Fetching recipes {offset + 1} to {offset + BATCH_SIZE}\")\n",
        "            batch = get_recipe_batch(offset)\n",
        "            if not batch:\n",
        "                print(\"No more data returned. Possibly hit limit.\")\n",
        "                break\n",
        "            for recipe in batch:\n",
        "                writer.writerow(extract_recipe_info(recipe))\n",
        "            time.sleep(6)  # API rate limiting\n",
        "\n",
        "    print(f\"Saved recipes to {CSV_FILE}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    save_recipes_to_csv()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD2xcwjGYI-v",
        "outputId": "ad0b6b81-3c1b-43af-d925-8a6b4bc7de74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching recipes 20001 to 20100\n",
            "Fetching recipes 20101 to 20200\n",
            "Fetching recipes 20201 to 20300\n",
            "Fetching recipes 20301 to 20400\n",
            "Fetching recipes 20401 to 20500\n",
            "Fetching recipes 20501 to 20600\n",
            "Fetching recipes 20601 to 20700\n",
            "Fetching recipes 20701 to 20800\n",
            "Fetching recipes 20801 to 20900\n",
            "Fetching recipes 20901 to 21000\n",
            "Fetching recipes 21001 to 21100\n",
            "Fetching recipes 21101 to 21200\n",
            "Fetching recipes 21201 to 21300\n",
            "Fetching recipes 21301 to 21400\n",
            "Fetching recipes 21401 to 21500\n",
            "Fetching recipes 21501 to 21600\n",
            "Fetching recipes 21601 to 21700\n",
            "Fetching recipes 21701 to 21800\n",
            "Fetching recipes 21801 to 21900\n",
            "Fetching recipes 21901 to 22000\n",
            "Fetching recipes 22001 to 22100\n",
            "Failed at offset 22000: 402\n",
            "No more data returned. Possibly hit limit.\n",
            "Saved recipes to recipes_data_2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "\n",
        "API_KEY = '6c6716d9526042f3854c309efdcdf20b'\n",
        "CSV_FILE = 'recipes_data_random_3000.csv'\n",
        "TOTAL_RECIPES = 3000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "def get_recipe_batch():\n",
        "    url = 'https://api.spoonacular.com/recipes/complexSearch'\n",
        "    params = {\n",
        "        'apiKey': API_KEY,\n",
        "        'number': BATCH_SIZE,\n",
        "        'addRecipeNutrition': True,\n",
        "        'sort': 'random'  # Ensures new recipes each time\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Request failed: {response.status_code}\")\n",
        "        return []\n",
        "    return response.json().get('results', [])\n",
        "\n",
        "def extract_recipe_info(recipe):\n",
        "    ingredients = ', '.join([ing['name'] for ing in recipe.get('nutrition', {}).get('ingredients', [])])\n",
        "    nutrients = {nutrient['name']: nutrient['amount'] for nutrient in recipe.get('nutrition', {}).get('nutrients', [])}\n",
        "    return [\n",
        "        recipe.get('id'),\n",
        "        recipe.get('title'),\n",
        "        ingredients,\n",
        "        nutrients.get('Calories', ''),\n",
        "        nutrients.get('Protein', ''),\n",
        "        nutrients.get('Fat', ''),\n",
        "        nutrients.get('Carbohydrates', '')\n",
        "    ]\n",
        "\n",
        "def save_recipes_to_csv():\n",
        "    collected_ids = set()\n",
        "    with open(CSV_FILE, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['ID', 'Title', 'Ingredients', 'Calories', 'Protein', 'Fat', 'Carbohydrates'])\n",
        "\n",
        "        total_collected = 0\n",
        "        while total_collected < TOTAL_RECIPES:\n",
        "            batch = get_recipe_batch()\n",
        "            if not batch:\n",
        "                print(\"No more data returned.\")\n",
        "                break\n",
        "            for recipe in batch:\n",
        "                recipe_id = recipe.get('id')\n",
        "                if recipe_id in collected_ids:\n",
        "                    continue  # Avoid duplicates\n",
        "                collected_ids.add(recipe_id)\n",
        "                writer.writerow(extract_recipe_info(recipe))\n",
        "                total_collected += 1\n",
        "                if total_collected >= TOTAL_RECIPES:\n",
        "                    break\n",
        "            print(f\"Collected: {total_collected}\")\n",
        "            time.sleep(6)\n",
        "\n",
        "    print(f\"Saved {total_collected} unique recipes to {CSV_FILE}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    save_recipes_to_csv()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTKzD6Hf1i2C",
        "outputId": "465444e7-7f33-4c23-8810-31209d1d1b07"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request failed: 402\n",
            "No more data returned.\n",
            "Saved 0 unique recipes to recipes_data_random_3000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "first prompt: suggest me the code to scrap only the vegetrian datas from the spoonacular website"
      ],
      "metadata": {
        "id": "2o1zde3M3xgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "last prompt :it is scrapping the same data already scrapped give me the code to scrap random data"
      ],
      "metadata": {
        "id": "74GHn7kN3qd4"
      }
    }
  ]
}