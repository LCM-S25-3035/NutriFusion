{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium pandas\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Setup headless browser\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Initialize driver\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# Keyword to search\n",
        "search_term = \"chicken\"\n",
        "search_url = f\"https://www.allrecipes.com/search?q=chicken\"\n",
        "\n",
        "# Load search page\n",
        "driver.get(search_url)\n",
        "time.sleep(5)  # wait for JS to load\n",
        "\n",
        "# Get recipe links\n",
        "recipe_links = []\n",
        "elements = driver.find_elements(By.CSS_SELECTOR, \"a.card__titleLink\")\n",
        "for elem in elements:\n",
        "    href = elem.get_attribute(\"href\")\n",
        "    if href and \"/recipe/\" in href:\n",
        "        recipe_links.append(href)\n",
        "\n",
        "recipe_links = list(set(recipe_links))  # unique\n",
        "\n",
        "print(f\"üîó Found {len(recipe_links)} recipes. Scraping each...\")\n",
        "\n",
        "# Scrape recipe content\n",
        "recipes_data = []\n",
        "for i, url in enumerate(recipe_links[:1000]):\n",
        "    try:\n",
        "        print(f\"‚û°Ô∏è  Scraping {i+1}: {url}\")\n",
        "        driver.get(url)\n",
        "        time.sleep(3)\n",
        "\n",
        "        title = driver.find_element(By.TAG_NAME, \"h1\").text.strip()\n",
        "\n",
        "        ingredients = [\n",
        "            ing.text.strip()\n",
        "            for ing in driver.find_elements(By.CSS_SELECTOR, \"span.ingredients-item-name\")\n",
        "        ]\n",
        "\n",
        "        instructions = [\n",
        "            step.text.strip()\n",
        "            for step in driver.find_elements(By.CSS_SELECTOR, \"li.subcontainer.instructions-section-item p\")\n",
        "        ]\n",
        "\n",
        "        recipes_data.append({\n",
        "            \"Title\": title,\n",
        "            \"Ingredients\": ingredients,\n",
        "            \"Instructions\": instructions,\n",
        "            \"URL\": url\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed at {url}: {e}\")\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(recipes_data)\n",
        "df.to_csv(f\"chicken_recipes.csv\", index=False)\n",
        "\n",
        "driver.quit()\n",
        "print(f\"‚úÖ Done. Saved recipes to chicken_recipes.csv\")\n"
      ],
      "metadata": {
        "id": "gVtJw2tAi3is"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}