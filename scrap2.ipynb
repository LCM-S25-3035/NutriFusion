{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aEE8K9eAwM4"
      },
      "outputs": [],
      "source": [
        "pip install requests beautifulsoup4 pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n"
      ],
      "metadata": {
        "id": "jn76FPvRDO4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def fetch_recipe_data_selenium(url):\n",
        "    options = Options()\n",
        "    options.headless = True  # Headless mode, no browser window\n",
        "\n",
        "    # Don't use user-data-dir to avoid session conflicts\n",
        "    # options.add_argument(f'--user-data-dir={temp_user_data_dir}')  # REMOVE THIS\n",
        "\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "\n",
        "    try:\n",
        "        driver.get(url)\n",
        "        print(f\"Loading {url} ...\")\n",
        "        time.sleep(7)  # wait for page to load fully\n",
        "\n",
        "        html = driver.page_source\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "        title_tag = soup.find('h1', class_='headline heading-content')\n",
        "        title = title_tag.get_text(strip=True) if title_tag else \"No title found\"\n",
        "\n",
        "        ingredients_tags = soup.select('li.ingredients__item')\n",
        "        ingredients = [tag.get_text(strip=True) for tag in ingredients_tags] if ingredients_tags else []\n",
        "\n",
        "        instructions_tags = soup.select('li.instructions-section-item div.section-body')\n",
        "        instructions = [tag.get_text(strip=True) for tag in instructions_tags] if instructions_tags else []\n",
        "\n",
        "        return {\n",
        "            'Title': title,\n",
        "            'Ingredients': ', '.join(ingredients),\n",
        "            'Instructions': ' '.join(instructions)\n",
        "        }\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    urls = [\n",
        "        'https://www.epicurious.com/recipes/food/views/spaghetti-carbonara-51217710',\n",
        "        'https://www.epicurious.com/recipes/food/views/chocolate-chip-cookies-51106320',\n",
        "        'https://www.epicurious.com/recipes/food/views/classic-deviled-eggs-56390335',\n",
        "        'https://www.epicurious.com/recipes/food/views/easy-roast-chicken-56390113',\n",
        "        'https://www.epicurious.com/recipes/food/views/banana-bread-51150870',\n",
        "    ]\n",
        "\n",
        "    all_recipes = []\n",
        "    for url in urls:\n",
        "        print(f\"Fetching: {url}\")\n",
        "        try:\n",
        "            data = fetch_recipe_data_selenium(url)\n",
        "            if data:\n",
        "                all_recipes.append(data)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch {url} due to error: {e}\")\n",
        "\n",
        "    if all_recipes:\n",
        "        df = pd.DataFrame(all_recipes)\n",
        "        df.to_csv('epicurious_recipes.csv', index=False)\n",
        "        print(\"Data saved to 'epicurious_recipes.csv'\")\n",
        "    else:\n",
        "        print(\"No recipes fetched.\")\n"
      ],
      "metadata": {
        "id": "cL-QnixfFQjf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}